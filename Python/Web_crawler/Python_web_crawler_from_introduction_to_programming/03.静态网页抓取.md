# 3 静态网页抓取
## 3.2 获取响应内容
```python
r = requests.get(link, headers, timeout)
```
* link：要请求的链接
* headers：传入的请求头，一般从网站获取
* timeout：超时响应

对于Requests对象的一些操作
* ```r.text```  服务器象用的内容，可根据响应头部的字符编码进行解码
* ```r.encoding```  服务器内容使用的文本编码
* ```r.status_code```  测试响应的状态码，通过返回值检测请求是否正确响应
	* 200：请求成功
	* 4xx：客户端错误
	* 5xx：服务器错误响应
* ```r.coontent```  字节方式的响应体，会自动解码 ```gzip``` 和 ```deflate``` 编码的响应数据
* ```r.json()```  Requests中内置的JSON解码器
举个栗子
```python
# 爬取豆瓣top250榜单的中文名及评分
# coding： UTF-8

import requests
from bs4 import BeautifulSoup


def getMovies():
    headers = {
        "user-agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36',
        "Host": 'movie.douban.com'
    }  # 输入网站的请求头，主要信息即user-agent和Host
    movie_list_cn = []
    movie_list_grade = []
    for i in range(0,10):
        link = "https://movie.douban.com/top250?start=" + str(i * 25)  # 找到网站的link模式，多页提取
        r = requests.get(link, headers=headers, timeout=10)
        print("第%d页响应状态码：" % (i + 1), r.status_code)
        soup = BeautifulSoup(r.text, "lxml")  # 格式化时传入的为r.text，指定“lxml”
        divlist1 = soup.findAll("div", class_="hd")  # 找到所有符合条件的指定目录
        # 1.如果某一标签有很多一样的，如都是span，则可使用findAll找出后使用索引，如下：
          div.findAll("span")[3]：指定div标签下众多span标签中的第四个
        divlist2 = soup.findAll("div", class_="star")
        for div1 in divlist1:
            cn = div.a.span.text  # 进入指定目录内包含所需信息的项，后用.text方法提取需要的字符
            movie_list_cn.append(cn)
        for div2 in divlist2:
            grade = div.find("span", {"class": "rating_num", "property": "v:average"}).text
            # 1.在使用div.div这种检索时，仍然可以使用find或findAll函数
            # 2.当某个标签下有多个属性时，只有把每个属性都写出来，才能匹配正确
            movie_list_grade.append(grade)
        cn_grade = dict(zip(movie_list_cn, movie_list_grade))  # dict函数将两个列表组成字典
    return cn_grade

movies = getMovies()
print(movies)
```

