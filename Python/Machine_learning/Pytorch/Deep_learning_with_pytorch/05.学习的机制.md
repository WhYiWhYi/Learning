# 5 学习的机制
机器学习：提出 一种输入数据与期望输出配对的学习算法。一旦学习发生，当向算法输入与训练时的输入数据**足够相似**的新数据时，该算法将能够产生正确的输出

深度学习：即使输入数据与期望的输出数据**相差甚远**时，学习算法也能工作

本章主要讲解如何自动化通用拟合函数（以最小化损失），以下是本章将实现内容的高度概括
* 给定输入数据和相应期望输出（实际数据）以及权重（参数）的初始值 
* 向模型输入数据（正向传播），并通过比较输出结果与实际数据来**评估误差**
* 优化模型参数：使用复合函数的导数的链式法则计算（反向传播，以更新权重值）**权重单位变化后的误差变化**（误差相对参数的梯度）
* 在**使误差减小**的方向上**更新权重值**
* 重复上述过程2~4，直至根据未知的数据评估的误差降到可接受的范围内
## 5.1 永恒的建模经验
我们将从数据中学习一些东西，即使算法从数据中学习。同样地，也可以表述为我们将**拟合数据**。在这个过程中总是涉及一个具有许多参数的函数，这些参数的值是从数据中估计出来的：简而言之，这就是模型。可以认为从数据中学习的假定基础模型并非解决特定问题，而是能够近似**更广泛的函数族**，其可以自动适应处理相似输入和输出对的任何任务
## 5.2 学习就是参数估计
示例：建立一个数据集，以我们选择的单位来表示刻度值和相应的温度值，选择一个模型，迭代地调整其权重，直到误差的度量足够低，最终能够以我们选择的单位来解释新的刻度值
### 5.2.2 数据准备
```python
# 基础数据
# t_c为摄氏度为单位的温度，t_u为我们未知的单位
t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])
t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])
```
当有了一组数据，可以将其可视化来看其大致的规律（低维数据可以，复杂的高维数据可能不行）
### 5.2.4 选择线性模型首试
在缺乏进一步了解的情况下，我们猜测这两组数据集可能是线性相关的，即 $t\_u$ 乘以一个因子（权重 $w$），加一个常数（偏置 $b$），我们就可以得到摄氏温度（忽略一定的误差）
* 权重：告诉我们给定的输入对输出的影响有多大
* 偏置：所有输入为零时的输出
$$
t\_c = w * t\_u + b
$$
现在我们将基于现有的数据来评估模型中的 $w$ 和 $b$ 参数，这样我们通过运行模型得到的位置温度 t_u 就会接近我们实际测量的摄氏温度（听起来就像是通过一组测量值来**拟合**一条直线）。

总结：我们有一个带有一些未知参数的模型，我们需要估计这些参数以使输出的预测值和测量值之间的**误差尽可能小**。神经网络的本质上是使用几个或一些参数将一个模型变换为更加复杂的模型
### 5.3 减少损失是我们想要的
我们需要精确定义误差的程度，这种程度通过**损失函数**来定义
* 损失函数（或代价函数）是一个计算单个数值的函数，其通常涉及获取一些训练样本的期望输出与输入这些样本是模型实际产生的输出之间的差值
* 如果误差很大，则说明损失函数的值大了，理想情况下应该尽可能使损失函数的值较小，这样预测值和测量值二者可以完美匹配。我们的优化过程应该以找到 $w$ 和 $b$ 为目标，使损失函数处于最小值。
* 当优化目标是最小化（minimize）时，我们自然地希望能最小化收敛到某个常数值，比如常见的0，于是一般来说需确保损失函数计算得到的损失为正
* 从概念上说，损失函数是一种对训练样本中要修正的错误进行优先处理的方法，因此参数更新会导致对高权重样本的输出进行调整，而不是对损失较小的其他样本的输出进行调整。依据所选择数学表达式的不同，可强调或忽略某些误差

在本节的例子中，最直接的损失函数为 $|t\_p - t\_c|$ 和 $(t\_p-t\_c)^2$。基于一些理由（详见原文），最终选择了 $(t\_p-t\_c)^2$ 作为本例的损失函数
```python
# 定义模型
# t_u：输入张量；w：权重参数；b：偏置参数
def model(t_u, w, b):
	return w * t_u + b

# 定义损失
# 构建了一个差分张量，先对其平方元素进行处理，最后通过对得到的张量中的所有元素求平均值得到一个标量损失函数，即均方损失函数
def loss_fn(t_p, t_c):
	squared_diffs = (t_p - t_c) ** 2
	return squared_diffs.mean()
```
【拓展】广播
Pytorch改写了在NumPy中流行的广播机制（只能对**相同形状**的参数使用基于元素的二元运算（加减乘除），每个张量中匹配位置的项将被用来计算与结果张量中相应的项），对大多数二元运算放宽了一些假定条件
* 向后向前迭代每个索引维度，如果该维度中有一个操作数的维度大小1，那么PyTorch将使用该维度上的单个项与另一个张量沿该维度上的每一项进行运算
* 如果两个维度大小都大于1，则它们的维度大小必须相同，并使用自然匹配
* 如果一个张量的维度大于另一个张量的维度，那么另一个张量上的所有项将和这些维度上的每一项进行运算
```python
x: torch.Size([])
y: torch.Size([3, 1])
z: torch.Size([1, 3])
a: torch.Size([2, 1, 1])

x * y
>>> torch.Size([3, 1])
y * z
>>> torch.Size([3, 3])
y * z * a
>>> torch.Size([2, 3, 3])
```
## 5.4 沿梯度下降
我们将根据参数，使用**梯度下降法**来优化损失函数。梯度下降是一个非常简单的概念，它可以很好地扩展到具有数百万个参数的大型神经网络模型。本节将描述如何手动去进行梯度下降（实际上可以通过PyTorch实现，详见5.5）
### 5.4.1 减小损失
梯度下降的思想是计算各参数的损失变化率，并在**减小损失变化率的方向上**修改各参数（反向传播）。在本节的例子中，可以通过在 $w$ 和 $b$ 上添加（或减少）一个小数字来估计损失变化率，即损失在这附近的变化有多大
```python
delta = 0.1  # “小数字”

loss_rate_of_change_w = \
(loss_fn(model(t_u, w+delta, b), t_c) - 
loss_fn(model(t_u, w-delta, b), t_c)) / (2.0 * delta)  #  b参数也可应用相同的
```
在 $w$ 和 $b$ 的当前值附近，$w$ 的增加会导致损失的一些变化。如果变化是负的，那我们需要增加 $w$ 来最小化损失；若变化是正的，我们需要减小 $w$ 的值

具体需要增加或减少可以靠对 $w$ 应用一个与损失的变化率成比例的变化，特别当损失有多个参数时：我们将一个变化应用于那些可以使损失产生重大变化的参数。另一种简单的方式使通过缓慢地改变参数，因为在距离当前 $w$ 值的邻域很远的地方，改变的速率可能会有显著不同。因此，我们通常应该用一个小的**比例因子**来衡量变化率。这个比例因子有很多名称，在机器学习中称为学习率（learning_rate）
```python
learning_rate = 1e-2
w = w - learning_rate * loss_rate_of_change_w  # 参数变更值=学习率*损失
```
通过重复以上评估步骤（当选择一个足够小的学习率），我们将收敛到在给定数据上使损失最小的参数的最优值
### 5.4.2 进行分析 
在参数较多的模型中，通过对模型和损失的重复评估来探测损失函数在 $w$ 和 $b$ 邻域的行为并计算变化率可能不太适合，尤其是我们还不知道邻域有多大。如果与delta相比损失变化太快，我们就无法很好地知道损失在哪个方向上减小得最快

而若当我们分析**所得到的损失对参数的导数**时，可以使邻域无限小。因此，在一个有2个或2个以上参数的模型中，我们计算每个参数的损失导数，并将它们放入一个导数向量中，即**梯度**
1. 计算导数：为了计算损失对一个参数的导数，我们可以应用链式法则，先计算损失对于其输入（模型输出）的导数，再乘以模型对参数的导数
	$$
	\frac {d\,loss\_fn}{d\,w} = (\frac {d\,loss_fn}{d\,t\_p}) \times 		\frac {d\,t\_p}{d\,w}
	$$
	```python
	# 定义loss_fn的导数，即(t_p - t_c) ** 2的导数
	def dloss_fn(t_p, t_c):
		dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)  # 这个除法来自均值的导数
		return dsq_diffs
	```

2. 将导数应用到模型中
	```
	# 模型对于参数w、参数b的导数
	def dmodel_dw(t_u, w, b):
		return t_u

	def dmodel_db
		return 1.0
	```
3. 定义梯度函数（返回梯度）
	```python
	def grad_fn(t_u, t_c, t_p, w, b):
		dloss_dtp = dloss_fn(t_p, t_c)
		dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)
		dloss_db = dloss_dtp * dmodel_db(t_u, w, b)
		return torch.stack([dloss_dw.sum(), dloss_db.sum()])
	```
对所有数据点取均值（求和后除以一个常数），得到损失的每个偏导数的单个标量
### 5.4.3 迭代以适应模型
当做好优化参数的准备后，可以从某参数的假定值开始，对它应用更新直到达到停止迭代的条件。这些条件可以是达成固定次数的迭代，也可以是直到 $w$ 和 $b$ 停止变化为止

迭代周期：我们称训练迭代为一个迭代周期，在这个迭代周期，我们更新所有训练样本的参数
1. 循环训练
	```python
def trainin_loop(n_epochs, learning_rate, params, t_u, t_c):
	for epoch in range(1, n_epochs+1):
		w, b =params
			
		t_p = model(t_u, w, b)  # 正向传播
		loss = loss_fn(t_p, t_c)
			
		grad = grad_fn(t_u, t_c, t_p, w, b)  # 反向传播
			
		params = params - learning_rate * grad
	return params
	```
2. 过度训练
	
	使用上述代码进行训练时训练过程崩溃了，损失趋向于无穷，这提示我们参数接收到的更新太大了，它们的值开始来回波动，因为每次更新修正过度，会导致下一次更新更加过度。优化过程是发散的而非收敛到最小值

	限制 ```learning_rate * grad``` 大小的一个简单方法是选择一个小的学习率（事实上，当训练进行得不像我们希望的那样好时，我们通常会改变学习率）。但是，当参数接收到的更新很小时，损失下降也会变得非常慢，最终停滞不前。这可以通过学习率自适应来解决，即根据更新的大小进行更改（详见5.5.2）
### 5.4.4 归一化输入
梯度本身也是一个潜在的问题。在第一个迭代周期权重的梯度约是偏置梯度的50倍，二者处于不同的比例空间中。这种情况下，若学习率足够大，则能够有效更新其中一个参数，但对于另一个参数来说学习率会变得不稳定，而一个只适合于另一个参数的学习率也不足以有意义地改变前者，即我们无法更新参数，除非我们改变模型的公式。每个参数都可以有自己的学习率，但是对于有很多参数的模型，这十分麻烦

一种简单的方式可以改善上述问题：改变输入。粗略来讲，可以通过确保输入的范围不会偏离-1.0 ~ 1.0太远，这样梯度就不会有太大的不同。一个有效的方法是对**参数**进行**归一化**。当梯度的大小相似时，可以对二者使用一个学习率（即便学习率调回1e-2，参数也不会在迭代更新中爆炸）。对于更大、更复杂的问题，使用归一化可以简单而有效的改进模型的收敛性
## 5.5 PyTorch自动求导：反向传播的一切
### 5.5.1 自动计算梯度
PyTorch张量可以记住它们自己从何而来，根据产生它们的操作和父张量，它们可以根据输入自动提供这些操作的导数链。这意味着我们不需要手动推导模型，给定一个前向表达式，无论嵌套方式如何，PyTorch都会自动提供表达式相对其输入参数的梯度
```python
params = torch.tensor([1.0, 0.0], requires_grad=True)

params.grad is not None
>>> True
```
```requires_grad=True``` 这个参数告诉PyTorch跟踪由对params张量进行操作后产生的张量的整个系谱树。即任何将params作为祖先的张量  都可以访问从params到那个张量调用的函数链。如果这些函数是可微的（大多数PyTorch张量操作都是可微的），导数的值将自动填充为params张量的grad属性

我们要做的是从一个 ```requires_grad=True``` 的张量开始，调用模型并计算损失，然后反向调用损失张量
```python
loss = loss_fn(model(t_u, *params), t_c)
loss.backward()  # 反向遍历自动求导图以计算梯度

params.grad  # params的grad属性包含关于params的每个元素的损失的导数
>>> tensor([4517.2969, 82.6000])
```
可以有任意数量的 ```requires_grad=True``` 的张量和任意组合的函数，这种情况下PyTorch将计算整个函数链（计算图）中损失的导数，并将它们的值**累加**到这些张量的grad属性中（图的叶节点）

* 单独的张量经过相同的函数得到的计算图是独立的

调用 ```backward()``` 将导致导数（即梯度）在叶节点上累加，因此如果提前调用 ```backward()```则会再次计算损失。再次调用 ```backward()```，从而导致梯度计算不准确（每个叶节点上的梯度将在上一次迭代中计算的梯度之上累加，输出的是此前所有迭代的梯度之和而非当前此轮迭代的梯度）。因此，需要在每次迭代时明确地将梯度归零
```python
# 完整的自动求导
def training_loop(n_epochs, learning_rate, params, t_u, t_c):
    for epoch in range(1, n_epochs+1):

        if params.grad is not None:  # 在循环中调用loss.backward()之前调用即可
            params.grad.zero_()

        t_p = model(t_u, *params)
        loss = loss_fn(t_p, t_c)
        loss.backward()  # 计算当前迭代的损失

        with torch.no_grad():
			params -= learning_rate * params.grad  # 变更参数
	return params
```
使用with，以及更新params张量位置的解释
* with：使用with语句将参数的更新封装在非梯度的上下文中，这意味着在with块中，PyTorch自动求导机制将不起作用，即不向前相图添加边。实际上，在执行这段代码时，PyTorch记录的前向图在我们调用 ```backward()``` 时被消费掉而留下params叶节点，但我们现在想在叶节点建立一个新的前向图之前改变它。诸如这样的锂离子通常被封装在5.5.2小节中所述的优化器中
* 更新params张量：可见保持相同的params张量但从中直接减去更新（即不创建新的张量，就地更新）。但使用自动求导时，通常避免就地更新，因为PyTorch的自动求导引擎可能需要我们修改反向传播的值。此处未进行自动求导操作，保持params张量是有益的
### 5.5.2 优化器
在模型复杂的时候，有一些优化策略和技巧可以帮助收敛，使用优化器避免了我们必须自己更新模型中的每个参数的繁琐工作

```torch.optim``` 中包含有多个实现不同优化算法的类。每个优化器的构造函数都接收一个参数列表（一个PyTorch张量，通常将requires_grad设置为True，参数列表可能很长，这是深度神经网络所需要的）作为第一个输入。传递给优化器的参数都保留在优化器对象中，这样优化器就能更新它们的值并访问它们的grad属性

以使用梯度下降优化器为例进行梯度计算（不同优化器的传参不一样，使用不同优化器时需注意）
```python
pramas = torch.tensor([1.0, 0.0], requires_grad=True)
learning_rate = 1e-2

# 创建梯度下降优化器
optim_sgd = optim.SGD([params], lr=learning_rate)

def training_loop(n_epochs, optimizer, params, t_u, t_c):
	for epoch in range(1, n_epochs+1):
		t_p = model(t_u, *params)
		loss = loss_fn
		
		optimizer.zero_grad()  # 调用backward()前初始化grad：将所有参数的grad属性（梯度）归零
		loss.backward()
		optimizer.step()  # 更新params的值
	return params
```
### 5.5.3 训练、验证和过拟合
在拟合模型时，需要评估训练集和验证集上的损失，在判断模型是否已经很好地与数据拟合时，必须同时考虑模型在训练集和验证集上的表现。一方面我们希望模型有足够的能力来拟合训练集，另一方面则需要避免模型出现过拟合，模型训练即在拟合和过拟合之间寻找平衡

模型在训练集上表现更好是合理的，因为模型是在参数是由训练集塑造的。我们的主要目的是同时减少训练损失和验证损失，在理想状态下，两种损失的值应大致相同，但只要验证损失与训练损失下降趋势相似、接近程度合理，就代表模型在继续学习关于数据集的一般性知识，有进行进一步优化的空间与可能

为神经网络选择合适的参数过程分为两步
* 增大参数直至拟合
* 缩小参数直至停止过拟合
1. 评估训练损失
	
	可通过训练损失来评估模型是否能够完全拟合训练集，即模型**是否有能力处理数据中的相关信息**。理论上深度神经网络可以潜在地近似复杂的函数，前提是神经元的数量和参数足够多
	```
	规则1：如果训练损失没有随着训练进行而减少，一种可能是因为模型对数据来说太简单了。当然也存在另一种可能，即数据没有有意义的信息以让模型对输出做出解释
	```
2. 推广到验证集
	
	如果在验证集中评估的损失没有随着训练集的增加而减少，意味着模型正在改进它在训练过程中看到的样本的拟合度，但它无法推广（泛化）到这个精确数据集之外的样本
	```
	规则2：如果训练损失和验证损失发散，则表明出现了过拟合现象
	```
	避免过拟合的思路
	* 确保有足够多的数据以确保模型在数据点之间的行为对我们试图近似的过程是合理的
	* 确保能够拟合训练数据的模型在数据点之间尽可能规律
		* 在损失函数中添加惩罚项以降低模型成本，使之表现更平稳、变化更缓慢（直至达到某一点）
		* 在输入样本中认为地创建噪声数据点并迫使模型取拟合它们
	* 让模型变得更简单。一个更简单的模型不会像一个复杂模型那样完美地拟合训练数据
3. 数据集分割
数据集分割：可以使用原本sklearn的数据集分割方式，也可尝试学习下PyTorch的数据集分割策略
	```python
	# 数据集分割后的训练循环
	def training_loop(n_epochs, optimizer, params,
				  	train_t_u, val_t_u,
				  	train_t_u, val_t_c):
		for epoch in range(1, n_epochs+1):
		
			# 训练模型+评估损失（训练集）
			train_t_p = model(train_t_u, *params)
			train_loss = loss_fn(train_t_p, train_t_c)
	
			# 训练模型+评估损失（验证集）
			val_t_p model(val_t_u, *params)
			val_loss = loss_fn(val_t_p, val_t_c)
		
			optimizer.zero_grad()
			train_loss.backward()  # 只在训练集上训练模型，因此只在训练集上调用backward()
			optimizer.step()
		
			if epoch <= 3 or epoch % 100 == 0:  # 同时观察训练集和测试集的损失情况
				print(f"Epoch {epoch},
				  	"Training loss {train_loss.item():.4f},"
				  	f"Validation loss {val_loss.item():.4f}")
		return params
	```
### 5.5.4 自动求导更新及关闭
无论如何优化，构建自动求导图都会带来额外的开销，在验证过程中完全可以放弃这些开销（因为不需要在验证集上进行损失优化），尤其是在模型具有上百万个参数的模型中

```torch.no_grad()```：上下文管理器，可关闭自动求导
```python
with torch.no_grad():
	val_t_p model(val_t_u, *params)
	val_loss = loss_fn(val_t_p, val_t_c)
```
```torch.set_grad_enabled```：基于布尔值判断启用或禁用自动求导条件
```python
def calc_forward(t_u, t_c, is_train):  # is_train是一个布尔值
	with torch.set_grad_enabled(is_train):
		t_p = model(t_u, *params)
		loss = loss_fn(t_p, t_c)
	return loss
```