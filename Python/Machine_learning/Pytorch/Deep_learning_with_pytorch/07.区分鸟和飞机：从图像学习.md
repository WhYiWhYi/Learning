# 7 区分鸟和飞机：从图像学习
## 7.1 微小图像数据集
### 7.1.1 下载CIFAR-10
使用 ```tprchvision``` 中的 ```datasets``` 模块提供了对最流行的计算机视觉数据集的预存储访问，这些数据集将作为 ```torch.utils.data.Dataset``` 的子类返回
```python
from torchvision import datasets

save_path = ""

# 参数1：数据储存位置；参数2：训练集/验证集；参数3：若在参数1指定位置未找到数据集，是否允许下载
cifar10 = datasets.CIFAR10(save_path, train=True, download=True)
cifat10_val = datasets.CIFAR10(save_path, train=False, download=True)
```
### 7.1.2 Dataset类
```torch.utils.data.Dataset``` 对象中实现了2种函数
* ```__len__()```：可返回数据中的项数。Python对象中配备了 ```__len__()``` 时，可以将其作为参数传递给Python的内置函数 ```len()```
	```python 
	len(cifar10)
	```
* ```__getitem__()```：可返回由样本和与之对应的标签。Python对象中配备了 ```__getitem__()``` 时，可以使用标准索引对元组和列表进行索引以访问单个数据
	```python
	img, label = cifar19[99]  # 同时返回样本机器标签
	class_names[label]  # 输出标签名字
	>>> img: (<PIL.Image.Image image mode=RGB size=32x32 at 0x7FB383657390>)
		1
	>>> 'automobile'
	```
### 7.1.3 Dataset变换
```torchvision.transforms``` 模块定义了一组可组合的、类似函数的对象，它可以作为参数传递到 ```torchvision``` 模块的数据集，在数据加载之后、```__getitem__()``` 返回之前对数据集进行变换，如将PIL图像变换为PyTorch张量

```ToTensor``` 对象可将NumPy数组和PIL图像变换为张量。它还将输出张量的尺寸设置为 $C \times H \times W$
```python 
from torchvision import transforms

to_tensor = transforms.ToTensor()  # 创建ToTensor对象（tensor转换器）
img_t = to_tensor(img)
img_t.shape
>>> torch.Size([3, 32, 32])  # 图像以转化为3×32×32的张量

# 将transforms模块中的“转换器”传递到datasets中
cifar10_t = datasets.CIFAR10(save_path, train=True, download=False, 								 transform=transforms.ToTensor())
img_t, label_t = cifar10_t[99]
>>> torch.Tensor  # 此时提取相同的样本，返回的就是张量而非PIL图像
	1

# 验证转换后的张量转化为图像后是否与原PIL图像相同
plt.imshow(img_5.permute(1,2,0))  # 将维度顺序修改为H×W×C以匹配Matplotlib的输入要求
plt.show()
```
### 7.1.4 数据归一化
归一化：使每个通道的均值为0，标准差为1
* 通过选择在0±1（或2）附近呈线性的激活函数，将数据保持在相同范围内意味着神经元更有可能具有非零梯度，从而更快地学习
* 对每个通道进行归一化，使其具有相同的分布，可以保证在相同的学习率下通过梯度下降实现通道信息的混合和更新

```transforms.Normalize()```：归一化，但均值和标准差需离线计算（自行计算，它们并不通过变化计算得到）
```python
imgs = torch.stack([img_t for img_t, _ in cifar10_t], dim=3)  # 在额外为维度堆叠数据集的图像

imgs.view(3, -1).mean(dim=1)  # 保留通道C所在的维度，将其他维度合并，然后在dim=1上计算均值
>>> torch([0.4915, 0.4823, 0.4468])
imgs.view(3, -1).std(dim=1)  # 在dim=1上计算标准差
>>> tensor([0.2470, 0.2435, 0.2616])

norm = tansforms.Normalize((0.4915, 0.4823, 0.4468),
                           (0.2470, 0.2435, 0.2616))  # 初始化归一化变换
```
可以使用 ```transforms.Compose``` 方便地将变换和归一化连续操作
```python 
cifar_10_trans = datasets.CIFAR10(data_path, train=True, download=False,
                                  transform=transfoms.Compose([
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.4915, 0.4823, 0.4468),
                                                           (0.2470, 0.2435, 0.2616))
                                 ]))
```

## 7.2 区分鸟和飞机
从CIFAR-10数据集中选出所有的鸟和飞机，并建立一个神经网络进行区分
## 7.2.1 构建数据集
从CIFAR-10数据集中选出所有鸟和飞机的样本，重构训练、验证数据集
```python
label_map = {0: 0, 2: 1}  # 飞机和鸟在原数据集中的标签为0和2，此处重新分配为0和1
class_names = ['airplane', 'bird']

# 重构仅包含飞机、鸟的数据集
cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0,2]]
cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0,2]]
```
### 7.2.2 一个全连接模型
分析数据空间结构，构建神经网络层次

图像是一组在空间结构（长、宽）中排列的数字。虽然还不知道如何处理空间结构部分，但理论上如果把图像像素拉成一个长的一维向量，就可以把这些数字当作输入特征，并运用线性模型

为了构建一个能学习任意函数的模型，一个神经网络至少需要一个隐藏层（激活层，也就是两个模块），否则它只是一个普通的线性模型。隐藏的特征表示经由权重矩阵编码的输入之间的（学习的）关系。因此模型可能会“比较“向量元素，但不会先验地关注它们。如模型会”比较“向量元素176和208，但模型并不知道这些确实是相邻的（第5行像素16和第6行像素16）

每个样本的特征数包括3×32×32，共3072个特征。我们将使用的线性模型将有3072个输入特征和一些隐藏的特征，接着是一个激活函数，然后另一个线性模型是网络的输出特征逐渐减少到适当的数量（就本例开始，Nout=2）
```python
import torch.nn as nn

n_out = 2
model = nn.Sequential(nn.Linear(3072, 512),  # 任意选择了512个中间隐藏特征
					  nn.Tanh(),
					  nn.Linear(512, n_out))
```
### 7.2.3 分类器的输出 & 7.2.4 用概率表示输出
本例的输出是分类的：样本要么是一只鸟，要么是一架飞机。当我们必须表示一个分类变量时，应该用该变量的**独热编码**表示，如对于飞机使用[1,0]，对于鸟使用[0,1]

理想情况下，网络将为飞机输出 ```torch.tensor([1.0, 0.0])```，为鸟输出 ```torch.tensor([0.0, 1.0])```。然而实际上我们构建的分类器并不是完美的，我们可以期望网络输出介于二者之间的结果，即将输出解释为概率：第1项是”飞机“的概率，第2项是”鸟“的概率。然而，根据概率来处理问题会对我们的输出施加一些额外的约束
* 输出的每个元素必须在[0.0, 1.0]范围内（概率值范围为[0,1]）
* 输出元素的总和必须为1.0（确信预测的结果必然在这两种结果范围内）

```Softmax``` 可获取一个值的向量并生成另一个相同维度的向量。通过该函数的操作，可以满足上述列出的表示概率的约束条件
* 具体实现为：取向量的元素，计算元素的指数，然后将每个元素指数除以元素指数之和
* ```Softmax``` 是一个单调函数（输入的较小值对应输出的较小值），但其尺度并非不变（输入值之间的比率在输出值之间并未保留）。但这并不是一个问题，因为学习过程将驱动模型的参数，使其值具有适当的比率
```python 
import torch.nn as nn

softmax = nn.Softmax(dim=1)  # 创建Softmax器，并指定用于编码概率的维度

model = nn.Sequential(nn.Linear(3072, 512),
					  nn.Tanh(),
					  nn.Linear(512, 2),
					  nn.Softmax(dim=1))  # 可以在模型末尾直接添加nn.Softmax()
```
为了调用模型，需要调整将输入具有正确的维度。```nn``` 处理的是沿着第0维成批组织的数据，因此需要将3×32×32的图像变成一个一维张量，并在第0个维度增加一个维度
```python
img_batch = img.view(-1).unsqueeze(0)  # img是随机取的一副鸟的图像

# 可以训练了
out = model(img_batch)
>>> tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward>)  # graf_fn在反向传播时使用
```
虽然可以得到一个概率，但是因为线性层的权重和偏置还没有训练过，因此此处得到的结果可以算是“偶然”

此外，虽然我们知道输出概率应该是多少，但是网络却无法分辨。在反向传播之后，损失函数将标签与输出的数字联系起来。如果提供的标签将“飞机”的索引设置为0，“鸟”设置为1，则这就是导出时的输出顺序。训练之后，可以通过计算输出概率的argmax来获取作为索引的标签，即最大概率的索引。```torch.max()``` 可同时返回指定维度上的最大元素及该值的索引
```python
max_value, index = torch.max(out, dim=1)
```
### 7.2.5 分类的损失
确定了模型和输出结果后，可以开始进行训练了。训练的目的与此前一样，都是减少损失。因此首先要明确要最小化的损失是什么，以及如何最小化它

此前的章节中，我们使用MSE作为损失，现在也仍可以继续使用MSE将输出概率收敛到[0.0, 1.0]和[1.0, 0.0]。然而，我们并非真的对精确地获取值感兴趣，而真正感兴趣的是不同值之间的大小关系。即对于飞机来说，第1个概率高于第2个，对于鸟类来说，第2个的概率高于第1个。因此，在本例中**惩罚错误分类**比惩罚看起来不完全像0.0或1.0的东西更重要

据此，我们需要最大化的是**与正确的类 out[class_index]（out是输出，class_index是向量，代表正确的分类标签）相关的概率**。这个与正确的类别相关的概率被称作模型给定参数的似然。总结来说，我们想要一个损失函数，在概率很低的时候，损失非常高：低到其他选择都有比它更高的概率，而当概率高于其他选择时，损失应该很低。同时，我们并不要求将概率提高至1

负对数似然（negative log likelihood, NLL）损失函数在预测目标类别的概率较低时，会增长到无穷大，而当预测目标类别概率大于0.5时，NLL的下降速度非常慢。由于NLL将概率作为输入，因此随着预测目标类别概率增加，其他的概率必然会减少。这符合我们的需要
$$
NLL = -sum(\log(out\_i[c\_i]))
$$
在Pytorch中有一个 ```nn.NLLLoss``` 类，其取**对数概率张量**和**类别索引张量**作为输入，然后在给定一批数据的情况下计算模型的NLL。取概率的对数是一件棘手的事情，因此我们将 ```nn.Softmax()``` 替换为 ```nn.LogSoftmax()``` 以确保计算数值稳定

综上所述，对于批次中的每个样本，分类损失可以按照如下步骤计算
* 正向传播，在最后的线性层获得输出值
* 计算输出值的Softmax，并获得概率
* 获取与目标类别对应的预测概率（参数的似然值）。因为是监督问题，所以我们知道目标类别
* 计算它的对数，在前面添加一个符号再添加到损失中
```python
model = nn.Sequential(nn.Linear(3072, 512),
					  nn.Tanh(),
					  nn.Linear(512, 2),
					  nn.LogSoftmax(dim=1))  # 修改为LogSoftmax

img, label = cifar2[0]
out = model(img.view(-1).unsqueeze(0))

loss = nn.NLLLoss()  # 创建负对数似然计算器
loss(out, torch.tensor([label]))
>>> tensor(0.6509, grad_fn=<NllLossBackward>)
```
事实上，```nn.LogSoftmax()``` 和 ```nn.NLLLoss()``` 的组合，相当于直接使用 ```nn.CrossEntropyLoss()```，交叉熵损失函数。具体替换方式为，在神经网络中丢弃最后一个 ```nn.LogSoftmax``` 并直接使用 ```nn.CrossEntropyLoss()``` 作为损失函数计算损失。唯一的问题是模型的输出不能解释为概率或对数概率了，因为需要 ```Softmax()``` 显示地传递输出来获得概率
### 7.2.6 训练分类器
```python
import torch
import torch.nn as nn

# 数据准备
train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)
val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)

# 训练用模型、学习率、优化器、损失函数
model = nn.Sequential(nn.Linear(3072, 512),
					  nn.Tanh(),
					  nn.Linear(512, 2),
					  nn.LogSoftmax(dim=1))
learning_rate = 1e-2
optimizer = optim.SGD(model.parameters(), lr=learning_rate)
loss_fn = nn.NLLLoss()

# 训练
n_epocs = 100
for epoch in range(n_epochs):
	
	for imgs, labels in traing_loader:
		
		batch_size = imgs.shape[0]
		outputs = model(imgs.view(batch_size, -1))
		loss = loss_fn(outputs, labels)
		
		optimizer.zero_grad()
		loss.backward()
		optimizer.step()
		
		print("Epoch: %d, Loss: %f" % (epoch, float(loss)))  # 输出的是随机批处理的损失

# 验证
correct = 0
total = 0

with torch.np_grad():
	for imgs, labels in val_loader:
		
		batch_size = imgs.shape[0]
		outputs = model(imgs.view(batch_size, -1))
		
		_, predicted = torch.max(outputs, dim=1)
		
		total += labels.shape[0]
		correct += int((predicted == labels).sum())

print("Accuracy: %f" % correct/total)
>>> Accuracy: 0.794000
```
在最终进行分类器训练时，部分细节内容描述如下
1. 更改训练循环
	
	在一个批处理中评估10000幅图像太多，于是正式代码中加入了一个内部循环：每次评估一个样本，然后在单个样本上反向传播
	
	需要注意的是，在无内部循环时，梯度在应用之前是在所有样本上累加的，而在加入内部循环后，将根据**对单个样本的梯度的部分估计对参数进行更改**。然而，基于一个样本的减小损失的好方向对于其他样本来说可能不是好方向，为此，需要引入随机性
2. 小批量采样

	因此，可以通过**在每个迭代周期上变换样本并一次估计一个或几个样本（为了稳定性）的梯度**有效地**引入随机性**。事实证明，在小批量上估计的梯度（这一梯度可看作是整个数据集中估计出的较差梯度的近似值）有助于收敛，且能防止优化过程在训练过程中陷入局部最小值
	
	在使用小批量时，小批量上的梯度会随机偏离理想轨迹（这也是为何要使用一个**较小学习率**的原因：不然单次训练可能导致偏离太远）。**每个迭代周期重新打乱数据集**有助于确保在小批量上估计的梯度序列（即一系列梯度）代表在整个数据集上估计的梯度
	
	```torch.utils.data.DataLoader``` 类可有助于打乱数据和组织数据。这种数据加载器的主要作用就是从数据集中采样小批量数据，使我们能够灵活选择不同的采样策略。其中一种十分常见的策略就是**在每个迭代周期洗牌后进行均匀采样**。DataLoader可以被迭代，因此可以很方便地应用于循环
	```python
	# batch_size: 取样量
	# shuffle：是否需要在每个的迭代周期开始时被重新打乱
	train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)
	```
可以添加更多层数来增加模型的深度和容量，但通过作者的测试，更大的模型虽然带来了更高的验证集准确率，但并未提升太多（0.802000），而训练集的准确率却达到了0.998100。这说明模型过拟合了
### 7.2.7 全连接网络的局限
【拓展】全连接神经网络（fully connected neural network, FCNN）是一种基础的人工神经网络结构，其中每个神经元于前一层和后一层的所有神经元相连接，形成一个密集结构

当在图像的一维视图中使用线性模块时，一方面我们允许将图像中的任何像素与可能和我们任务有关的其他像素进行组合；另一方面，我们没有利用到相邻或远处像素的相对位置，因为图像被当作了一个大的数字向量。用专业术语来说，**全连接网络并非平移不变的**（如，一个经过训练能从位置(4,4)开始识别配其实飞机的网络将无法识别与之完全相同但是位置从(8,8)开始的飞机）。在训练时必须增强数据集，即对图像应用随机变换，这样神经网络就有机会在整幅图像上看到飞机。但是这种数据增强策略是有代价的：隐藏特征（参数）的数量必须足够大以存储所有已转换副本的信息