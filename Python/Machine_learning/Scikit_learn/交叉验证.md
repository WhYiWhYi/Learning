## 1 将数据分割为训练集和测试集（及验证集）

训练集和测试集
* 使用原因
	* 将数据集合理分配为训练集和测试集，可使用训练集的数据训练模型，然后用测试集上的误差作为**最终模型在应对现实场景中的泛化误差**，这样即可避免在部署环境和训练模型之间往复（代价往往较高），也可使用模型对测试数据的拟合程度作为近似代表模型泛化能力
	* 有了测试集，我们想要验证模型的最终效果，只需将训练好的模型在测试集上计算误差，即**可认为此误差即为泛化误差的近似**，我们只需让我们训练好的模型在测试集上的误差最小即可
* 使用训练集测试集注意
	* 常规数据分割：80%作为训练集，20%作为测试集
	* 需在**开始构建模型之前划分数据集，防止数据窥探偏误**。即避免因了解太多关于测试集样本的特点而导致模型测试得到更乐观（虚假的乐观）的结果
	* 在构建模型前进行的数据前处理，如数据清洗、数据特征缩放等操作**只能在训练集上进行**，**测试集将直接应用由训练集处理得到的参数**（如使用由训练集数据得到的中位数填补测试集中缺失值）
	* 进行模型选择时，可对比他们在测试集上的误差，选择**泛化能力强的模型**
* 数据集分割方法
	* 随机采样
		* 自己实现训练集测试集分割
        ```python
        import numpy as np
        def split_train_test(data, test_ratio, random_seed)
            np.random.seed(random_seed)  # 设置随机数种子

            shuffled_indices = np.random.pernutation(len(data))  # 随机生成0-len(data)随机序列

            test_size = int(len(data) * test_ratio)  # 计算测试集样本数
            # 此处针对随机序列生成训练、测试集，在返回值时要将其对其为原始data（使用iloc）
            train_indices = shuffled_indices[:test_size]
            test_indices = shuffled_indices[test_size:]
            return data.iloc[train_indices], data.iloc[test_indices]  # iloc选择参数序列中指定行
        ```
		* 使用sklearn库
        ```python
        from sklearn.model_selection import train_test_split

        x = datax  # 特征参数
        y = datay  # 标签参数

        # 对x和y使用相同的比例、随机数种子进行训练、测试集分割（确保分割的结果一一对应）
        x_train, x_test = train_test_split(x, test_size=0.2, random_state=42)
        y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)
        ```

	* 分层采样
以上两种数据集分割方式均为随机采样，这种方式对于**大量数据集**或**目标值分布均匀**的情况是可行的。而对于样本比例不均衡的样本（如二值分类器中，正例90%，反例10%），随机抽样会导致标签分布不均匀，模型训练效果不佳。针对此类模型，需要采用分层采样的方式进行划分数据集
		* 使用sklearn库
        ```python
        import numpy as np
        import pandas as pd
        from sklearn.model_selection import StratifiedShuffleSplit

        x = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
        y = np.array([0, 0, 1, 1])

        # n_splits：分割迭代的次数，只分割一次则设置为1即可
        split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)

        for train_index, test_index in split.split(x, y):  # split.split获取的是分割的index
            x_train, x_test = x[train_index], x[test_index]  # 由索引提取数据
            y_train, y_test = y[train_index], y[test_index]

        # 获取抽取的各个样本的比例
        train_data = pd.DataFrame(y_train)  # y_train可以转化为任意训练集、测试集
        train_data.info()  # 获取y_train的信息

        # 计算各个类别的比例
        # n为类别项所在的列编号。如果特征和标签分别储存在两个array中，则对y_train/y_test计算时，n=0
        print(train_data[n].value_counts() / len(train_data))
        ```

验证集
* 使用原因
	* 当并非进行两个模型之间的对比，而是**对模型本身进行选择**，如调整神经网络中的多个**超参数**时。一般来说，可使用**测试集**来检验不同超参数下的结果进行泛化误差估计。但可能模型在测试集上的误差为0，但是这样的模型部署到真实场景中去使用，效果可能会非常差。这样的现象称**信息泄露**
	* 信息泄露的一般性解释：在调整模型时，如果使用最终用于测试的数据集进行模型调整，相当于知道了考试题目并学会怎么做题（当人为调整“超参”使模型在测试集上误差最小，相当于教会了模型怎么去“做题”）。再使用这些数据进行测试时，模型理所应当地能获得很好的结果。测试集将数据信息泄露给模型的过程，即信息泄露
	* 为了应对信息泄露，在学习的时候，准备一些小测试来进行查漏补缺，用于调整模型的依据，这些小测试即**验证集**
	* 最终，调整模型时，**在训练集上训练模型，在验证集上评估模型，一旦找到的最佳的参数，就在测试集上最后测试一次**，测试集上的误差作为泛化误差的近似
	* 训练集、验证集、测试集比例设置
		* 数据量不是很大时（万以下）：6：2：2
		* 数据量很大：98：1：1
		* 数据量很少：采用一些高级的办法，如留出法、K-fold交叉验证等
## 2 使用交叉验证检验模型准确性
### 2.1 交叉验证概述

在调整模型时，为了能让模型更加稳定，需使用数据集的不同子集进行反复的验证。如果只是针对特定子集进行调整，则可能会导致模型**过度拟合**。即，对于已知数据集拟合地很好，但对于未知数据集效果会大打折扣，为此，需要使用**交叉验证（cross-validation, CV）**

交叉验证的基本思想为：通过对**训练集**进行分割，生成**子训练集**和**子验证集**，使用子训练集对模型进行训练，使用子验证集对模型进行验证，最后再使用**测试集**对模型进行评估
* 举例：K-fold CV
	* K-fold CV将训练集划分为k个较小的集合（k-fold）
	* 在每次进行拟合时，使用k-1份集合作为子训练集，剩下的1份作为子验证集，重复进行k次
	* k-fold CV得到的性能指标是循环计算中每个值的平均值，其虽然计算代价很高，但是不会浪费太多的数据，在处理样本数据集较少的问题（例如，逆向推理）时比较有优势

计算交叉验证的方法
* corss_val_score(estimator, x, y, scoring, cv)
	* estimator：要进行评估的评估器（分类器、回归器、聚类器等）
	* x, y：投入计算正确率的数据，x_train, y_train或x_test, y_test
	* scoring：默认值为None，此时默认计算的是estimator的 ```score``` 方法。可以通过修改参数来改变评估方式和计算内容，具体见https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter，为要计算的项，依据不同模型（分类、回归、聚类）可有不同的参数
	* cv：交叉验证，默认值为5。当评估分类器，且y为分类标签时，交叉验证使用StraitifiedKFold，除此以外均使用KFold。此外，也可以传入一个交叉验证迭代器来使用其他交叉验证策略
	```python
	from sklearn.model_selection import corss_val_score
	from sklearn.model_selection import ShuffleSplit
	
	score = model_selection.cross_val_score(classifier, x, y, cv=5)
	
	# 传入其他交叉验证迭代器
	cv_shuffile = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)
	score = model_selection.cross_val_score(classifier, x, y, cv=cv_shuffile)
	```
* corss_validate(estimator, x, y, scoring, cv, return_train_score, return_estimator)
	* 各个参数的含义基本与 ```corss_val_score``` 相同
	* scoring：可传入含多个指标的**列表**。如果传入None，则默认值为 ```['test_score', 'fit_time', 'score_time']```，传入列表时，值为 ```['test_score1', 'test_score2', ..., 'fit_time', 'score_time']```
	* return_train_score：默认值为True，增加了所有scorers的训练得分keys
	* return_estimator：设置为True时，可保留所有在训练集上拟合好的估计器
	```python
	from sklearn.model_selection import cross_validate
	
	scoring = ['precision_weighted', 'recall_weighted']
	scores = cross_validate(classifier, x, y, scoring=scoring, cv=5)
	scores.keys()  # 输出传入的指标参数
	scores['test_recall_weighted']  # 从scores中查看指定参数（来自scores.keys()），会返回该参数计算的结果
	```
### 2.2 交叉验证迭代器
#### 2.2.1 循环遍历数据的交叉验证迭代器

1.K-fold

K-fold将训练集（含n个样本）划分为k个较小的集合（k-fold），每个集合中包含 n/k 个样本在每次进行拟合时，使用k-1份集合作为子训练集，剩下的1份作为子验证集，重复进行k次
* k（下面的n_splits）的设置既影响**训练集分割数目**，也影响**重复进行数目**
* 若k=n，则K-fold等效于Leave one out策略
* **K-fold（及其衍生的各种类型）不受分类影响**
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.1.K-fold.png)
```python
from sklearn.model_selection import KFold

x = []  # 待分割的训练集数据
y = []

# n_splits：指定的k值（分割次数）
# shuffle：可选参数，值为True或False，决定分割数据集时是否采用随机的方式
kf = KFold(n_splits=2, shuffle=False)
for train, test in kf.split(x):  # 此处获得的仅为索引（使用x或y均可），还需进行下一步的分配
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
2.Repeated K-Fold

指定参数后，可重复运行 ```KFold``` n次，每次重复都会产生不同的分割。类似地， ```RepeatedStratifiedKFold``` 在每次重复中都将随机重复n次分层的K-Fold

```python
from sklearn.model_selection import RepeatedKFold

x = []  # 待分割的训练集数据
y = []

# n_splits：指定的k值
# n_repeats：K-fold重复执行的次数
# random_state：随机数种子
rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=0)
for train, test in rkf.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

3.Leave One Out (LOO) & Lave P Out (LPO)

LOO将训练集（含n个样本）划分为n-1个样本组成的子训练集和剩下的一个样本组成的子验证集。LOO是K-Fold中k=n时的特例
* 对于n个样本，可产生n个不同的训练集和n个不同的测试集
* 这类交叉验证不会浪费太多数据。但由于n个样本中有n-1个被用于训练，折叠所构建的模型实际上是相同的，且相当于从整个训练集建立的模型
* 作为一般规则，大部分作者和经验表明，5-fold或10-fold交叉验证要优于LOO

LPO与LOO十分相似，其从训练集（含n个样本）中删除p个样本来创建**所有可能的子训练/验证集**
* 与LOO、K-Fold不同，**当p设置大于1时，测试集的个体会发生重叠**
```python
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import LeavePOut

x = []  # 待分割的训练集数据
y = []

# LOO
loo = LeaveOneOut()
for train, test in loo.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
	
# LPO
lpo = LeavePOut(p=3)  # 设置剩下的样本数
for train, test in lpo.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

4.Shuffle & Split (随机排列交叉验证)

**设置指定的训练/验证集比例**后，原始训练集首先被打散，然后按照比例随机选择样本组成子训练/验证集

* 可用于替代K-Fold，因为其可控制子训练/验证集的比例划分
* 对于数据量较大的数据，需要注意分割次数
* **ShuffleSplit不受分类影响**
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.1.ShuffleSplit.png)
```python
from sklearn.model_selection import ShuffleSpilt

x = []  # 待分割的训练集数据
y = []

ss = ShuffleSpilt(n_splits=3, test_size=0.25, random_state=0)
for train, test in ss.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
#### 2.2.2 基于类标签、具有分层（y）的交叉验证迭代器
1.Stratified K-Fold

K-Fold的变种，在对训练集进行分割时，会返回分层的结果：每个小集合中，各个类别的样例比例大致和完整数据集中相同。```RepeatedStratifiedKFold``` 可用于在每次重复中都将随机重复n次分层的K-Fold
* 在类别略不均衡的情况下也可应用
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.2.StratifiedK-fold.png)
```python
from sklearn.model_selection import StratifiedKFold

x = []  # 待分割的训练集数据，x和y均需为array
y = []

# n_splits：分割次数（不能大于每一类中的样本数），即生成多少组训练/测试数据；注意分割是对投入所有数据进行分割
# shuffle：可选参数，值为True或False，决定分割数据集时的数据采样是否采用随机的方式
# 默认按照8:2的比例分割训练集和测试集
skf = StratifiedKFold(n_splits=2, shuffle=False)
for train, test in skf.split(x, y):  # 此处输入两个参数x、y，其中y用于提供数据的分层信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
2.Stratified Shuffle & Split

Shuffle & Split的变种，在对训练集进行分割时，会返回分层的结果。子集中每个类的比例都与完整数据集相同
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.2.StratifiedShuffleSplit.png)

```python
from sklearn.model_selection import StratifiedShuffleSplit

x = []  # 待分割的训练集数据，x和y均需为array
y = []

# n_splits：分割次数（可大于每一类中的样本数），即生成多少组训练/测试数据；注意分割是对投入所有数据进行分割
# train_size / test_size：设置训练集和测试集的比例
sss = StratifiedShuffleSplit(n_splits=3, test_size=0.25, random_state=0)  # 参数类别与ShuffleSplit相同
for train, test in sss.split(x, y):  # 此处输入两个参数x、y，其中y用于提供数据的分层信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
#### 2.2.3 用于分组（group）数据的交叉验证迭代器
如果模型训练的结果依赖于样本的group，则进行的假设就不成立。举个例子，如果从多个患者身上收集数据，每个患者采集多个样本，此时如果收集的数据受到个体影响很大时，每个患者的ID就是组标识符（group identifier）。在这种情况下，我们想知道**在一组特定的group上训练的模型，是否能够很好地适用于未参与训练的group**，为此，需要确保**验证集中所有样本来自训练集中完全未出现的组**

1.Group K-Fold

K-Fold的变体，实现同一个group的数据不会在测试和训练集中同时出现
* 由于group数据可能不平衡，因此每次分割得到的子训练集和子验证集的大小并不完全相同
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.3.GroupK-fold.png)
```python
import numpy as np
from sklearn.model_selection import GroupKFold

x = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10])
y = np.array(["a", "b", "b", "b", "c", "c", "c", "d", "d", "d"])
groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

gkf = GroupKFold(n_splits=3)  # 分割次数
for train, test in gkf.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

2.Leave One Group Out (LOGO) & Leave P Group Out (LPGO)

LOO的变体，LO(P)GO将训练集（含n个样本）依据提供group的信息划分为n-1（n-p）个组的样本组成的子训练集和剩下的一（P）个组的样本组成的子验证集
* 提供的group信息需为整数组成的数组
```python
import numpy as np
from sklearn.model_selection import LeaveOneGroupOut, LeavePGroupsOut

x = np.array([1, 5, 10, 50, 60, 70, 80])
y = np.array([0, 1, 1, 2, 2, 2, 2])
groups = [1, 1, 2, 2, 3, 3, 3]

# LOGO
logo = LeaveOneGroupOut()
for train, test in logo.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
	
# LPGO
lpgo = LeavePGroupsOut(n_groups=2)  # 设置剩下的组数
for train, test in lpgo.split(x, y, groups=groups):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

3.Group Shuffle Split
该方法是 ```ShuffleSplit``` 和 ```LPGO``` 的组合，其按照比例随机选择若干个组的样本组成子训练/验证集
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.3.GroupShuffleSplit.png)
```python
import numpy as np
from sklearn.model_selection import GroupShuffleSplit

x = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])
y = np.array(["a", "b", "b", "b", "c", "c", "c", "a"])
groups = [1, 1, 2, 2, 3, 3, 4, 4]

gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)
for train, test in gss.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```