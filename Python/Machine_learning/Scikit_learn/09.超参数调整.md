## 1.调整超参数

超参数，指直接作为估计器类中构造函数的参数传递入估计器，而非通过估计器学习得到的参数。如SVM中的 ```C```、```kernal```、```gamma``` 等。超参数的设置对估计器的估计性能有所影响，因此**搜索超参数空间**以获得最好的交叉验证结果（分数）的方法。使用该种方法，构造估计器时所提供的任何参数（可通过 ```estimator.get_params()``` 获取）都可能被优化
### 1.1 网格搜索法

```GridSearchCV``` 通过 ```param_grid``` 参数提供的网格参数值中进行全面的网格搜索。其实现了常用的估计器API：**当在数据集上拟合时，参数值的所有可能组合都会被评估，从而计算出最佳的组合**

```python
from sklearn.model_selection import GridSearchCV

param_grid = [
	{"C": [1, 10, 100, 1000], "kernel": ["linear"]},
	{"C": [1, 10, 100, 1000], "gamma": [0.001, 0.0001], "kernel": ["rbf"]}
]  # 通过两套参数设置，分别进行网格搜索
```

GridSearchCV
link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html

* Parameters
	* estimator: 需提供 score 评分函数的估计器对象
	* param_grid: 网格搜索的参数空间设置
		* dict: 以参数名称为key，以参数具体设置列表为value的字典
		* list: 上述字典构成的列表（即多批参数设置）
	* scoring: 用于对交叉验证测试集结果进行评估的策略
		* **None**: 默认设置
		* single score: 仅使用单一指标评估
			* str: 通过字符串设置评价指标（详细可见06.2.3-RFECV部分）
			* callable: 自定义指标，返回值为单一值
		* multiple score: 使用多种指标评估
			* list/tuple: 包含多个单一字符串设置的评价指标
			* callable: 自定义指标，返回值为字典（key为参数名字，value为参数得分）
			* dict: key为参数名字，value为callable
	* n_jobs: 是否使用多核进行
		* **None**: 不做设置（默认设置）
		* int: 使用设置核心数
		* -1: 使用所有核
	* refit: 使用找到的最佳超参数对整个数据集上进行再次评估，并得到最终的性能评估分数。
		* **True**: 默认设置
		* str: 在有多个评估参数时，需使用字符串指定某一评分标准下的最佳超参数，该参数将作为refit的最佳超参数
	* cv: 决定交叉验证所使用的分割策略。若输入值为None或整数，如果分类为二元或多分类，则会使用StratifiedKFold（分层的交叉验证），否则（非二元或多分类）将会使用KFold进行交叉验证
		* **None**: 使用默认5-fold交叉验证（默认设置）
		* int: 使用n-fold交叉验证
		* cross-validation generator or iterable: 通过model_selection中交叉验证进行设置的交叉验证对象
	* verbose: 控制输出信息的详细程度
		* \>1: 显示每一cv和参数候选的计算时间
		* \>2: 显示分数
		* \>3: cv、候选参数索引、计算的开始时间均显示
	* pre_dispatch: 设置在进行并行作业时的分派的任务数量。当调度的任务多于CPU可以处理的数量时，可能会导致内存的激增，此时需减少该数值以避免内存的消耗
		* **"2*n_jobs"**: 默认设置（该str可以改为任意与n_jobs相关的表达式）
		* None: 所有的任务立即创建并生成，适合轻量级、快速运行的作业
		* int: 指定同时产生总任务数
	* error_score: 在估计器拟合发生错误时，评分的值。该参数不影响refit步骤
		* **np.nan**: 默认设置
		* "raise": 报错
		* numeric: 报错（FitFailedWarning）
	* return_train_score: 是否输出训练集的得分。训练集的得分可用于判断模型是否发生了过拟合或欠拟合。需注意增加训练集得分的输出将显著增加计算消耗
		* **False**: 在Attribute的cv_results_中将不包含训练集的得分结果（默认设置）
		* True: 在Attribute的cv_results_中包含训练集的得分结果
* Attributes
	* cv_results_: 生成一个储存结果的字典
		```python
		# 示例
		{
	'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],
                             mask = [False False False False]...)
	'param_gamma': masked_array(data = [-- -- 0.1 0.2],
                            mask = [ True  True False False]...),
	'param_degree': masked_array(data = [2.0 3.0 -- --],
                             mask = [False False  True  True]...),
	'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],
	'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],
	'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],
	'std_test_score'     : [0.01, 0.10, 0.05, 0.08],
	'rank_test_score'    : [2, 4, 3, 1],
	'split0_train_score' : [0.80, 0.92, 0.70, 0.93],
	'split1_train_score' : [0.82, 0.55, 0.70, 0.87],
	'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],
	'std_train_score'    : [0.01, 0.19, 0.00, 0.03],
	'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],
	'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],
	'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],
	'std_score_time'     : [0.00, 0.00, 0.00, 0.01],
	'params'             : [{'kernel': 'poly', 'degree': 2}, ...],
	}
		```
	* best_estimator_
	* best_score_
	* best_params_: 仅refit=True时可用
	* best_index_: 仅refit=True时可用
	* scorer_
	* n_splits_
	* refit_time_
	* multimetric_
	* classes_
	* n_features_in_
	* feature_names_in_
* Methods
	* decision_function
	* fit
	* get_params
	* inverse_transform
	* predict
	* predict_log_proba
	* predict_proba
	* score
	* score_samples
	* set_params
	* transform

```python
# 基于交叉验证的网格搜索参数估计

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.svm import SVC

# 导入数据集
digits = datasets.load_digits()

# 训练集、测试集划分
n_samples = len(digits.images)
x = digits.images.reshape((n_samples, -1))
y = digits.target
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=0)

# 设置交叉验证相关参数，进行交叉验证
tuned_params = [
    {"kernel": ["rbf"], "gamma": [1e-3, 1e-4], "C": [1, 10, 100, 1000]},
    {"kernel": ["linear"], "C": [1, 10, 100, 1000]}]
scores = ["precision", "recall"]  # 使用两种评分标准

for score in scores:  # 基于每一种评分标准进行网格搜索
	print("# Tuning hyper-parameters for %s" % score)  # 基于xx标准对超参数进行评估
	
	clf = GridSearchCV(SVC(), tuned_params, scoring="%s_macro" % score)  # 使用macro
	clf.fit(x_train, y_train)
	
	print("Best parameters set found on development set:")  # 基于参数组找到的最佳参数(refit默认开启)
	print(clf.best_params_)
	
	print("Grid scores on development set:")  # 网格搜索时的得分结果（此处输出的测试集结果）
	means = clf.cv_results_["mean_test_score"]
	stds = clf.cv_results_["std_test_score"]
	for mean, std, params in zip(means, stds, clf.cv_results_["params"]):
		print("%0.3f (+/-)%0.03f) for %r" % (mean, std, params)
	
	print("Detailed classification report:")  # 输出分类报告详情
	y_true, y_pred = y_test, clf.predict(x_test)
	print(classification_report(y_true, y_pred))
```
```python
# 使用GridSearchCV进行嵌套与非嵌套交叉验证（对比）
# 非嵌套CV（non-nested cross-vaidation）：即传统CV，仅将数据集拆分为训练集和测试集，无法解决最优模型的选择和模型调参的问题。传统CV由于使用相同的数据来调整摩西那个参数和评估模型准确性，其有两个弊端：1.可能造成信息泄露导致过拟合；2.导致较高的偏差（用可能的模型最佳超参数对相同的训练集和测试集进行误差的计算时，模型是有偏的，会导致较大偏差）
# 嵌套CV（nested cross-validation）：嵌套交叉验证通过对基础模型泛化误差的估计来进行超参数的搜索，以得到模型最佳参数。注意，当数据量很大时，使用嵌套CV的计算成本会很高。此外，有文章中提到，使用RFC、SVM、GBC等算法时，很可能不需要嵌套CV；使用分类算法时，嵌套CV可能不需要使用
# 为了避免传统CV的弊端，嵌套CV使用了一系列训练、验证、测试集的拆分。其运行流程包含外层循环和内层循环。内层循环指代有搜索模型最佳超参数功能的CV（本例中由GridSearchCV实现），目的是给外层循环提供模型的最佳超参数，外层循环除了给内层循环提供训练数据外，也保留部分数据用于对内层循环模型的测试。通过这一方式，可防止数据的信息泄露，得到相对较低的模型评分偏差
# 简单理解：就是将一组数据分为训练、验证、测试集。外层循环中，data分为out_train和out_test，其中out_train将作为inner_data进一步细分为inner_train和inner_test寻找最佳超参数，寻找到的最佳超参数则用于out_test进行测试并得到评分。out_test评分的均值即为模型表现的估计值

from sklearn.datasets import load_iris
from matplotlib import pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, cross_val_score, KFold
import numpy as np

# 导入数据集
iris = load_iris()
x = iris.data
y = iris.target

# 参数设置
num_trials = 30  # 训练次数
param_grid = {"C": [1, 10, 100], "gamma": [0.01, 0.1]}  # GridSearchCV的备择参数
non_nested_scores = np.zeros(num_trails)  # 储存非嵌套CV结果
nested_scores = np.zeros(num_trails)  # 储存嵌套CV结果

# 创建分类器
svm = SVC(kernel="rbf")

# 每一训练次数下执行的循环
for i in range(num_trials):
	# 设置外层循环和内层循环所使用的CV方式及具体参数，此处二者均选用KFold
	inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)
	outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)
	
	# 非嵌套CV（仅外层）
	clf = GridSearchCV(estimator=svm, param_grid=param_grid, cv=outer_cv)
	clf.fit(x, y)
	non_nested_scores[i] = clf.best_scores_  # 储存结果
	
	# 嵌套CV（双层）
	clf = GridSearchCV(estimator=svm, param_grid=param_grid, cv=inner_cv)  # GridSearchCV为内层循环
	nested_score = cross_val_score(clf, x=x, y=y, cv=outer_cv)  # 普通CV为外层循环
	nested_scores[i] = nested_score.mean()

score_difference = non_nested_scores - nested_scores  # 计算嵌套和非嵌套交叉验证的差值
```
```python
# 多评价指标下应用GridSearchCV

from sklearn.datasets import make_hastie_10_2
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier

# 创建数据集
x, y = make_hastie_10_2(n_samples=8000, random_states=42)

# 评估指标
scoring = {"AUC": "roc_auc", "Accuracy": make_scorer(accuracy_score)}  # "Accuracy"为自建指标

# 进行网格搜索
gs = GridSearchCV(
	DecisionTreeClassifier(random_state=42),
	param_grid={"min_sample_split": range(2, 403, 10)},
	scoring=scoring,
	refit="AUC",
	return_train_score=True)
gs.fit(x,y)
results = gs.cv_results_
```
### 1.2 验证曲线&学习曲线
每种估计器都有其优势和缺陷，一般而言，我们更希望使用具有**更小泛化误差**的估计器。泛化误差可分解为**偏差**、**方差**和**噪声**。偏差是不同训练集的平均误差，方差表示它对训练集变化的敏感程度，噪声则是数据的一个属性
在简单的一维问题中，很容易可看出估计值是否存在偏差或方差，而高维空间中的模型难以具象化，此时，可以借用验证曲线或学习曲线进行估计
#### 1.2.1 验证曲线
在应用 ```GridSearchCV``` 进行超参数估计时，其基于一个或多个验证集的最高得分来选择超参数。然而，如果基于验证分数优化了超参数，那基于优化后超参数的模型得到的验证分数就存在偏差，且不再是一个良好的泛化估计。为了得到正确的泛化估计，须在**另一个测试集上计算得分**
评估**单个超参数**对训练分数和验证分数的影响，有助于发现该估计是否因为某些超参数的值出现**过拟合（训练集结果很好而测试集结果差）**或**欠拟合（训练集和测试集结果都较差）**

validation_curve
link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html#sklearn.model_selection.validation_curve

* Parameters
	* estimator: 具有 fit 和 predict 方法的估计器对象
	* x: 特征集
	* y: 分类集
		* None: 用于非监督估计器
	* param_name: 用于验证的单个超参数的名称
		* str: 用于验证的超参数名称的字符串
	* param_range: 超参数验证的范围
		* array-like of shape: 格式为数组的，用于验证的超参数范围
	* groups: 在分割训练集测试集时使用的分组标签，仅当在CV中选用相应方法（如 GroupKFold）时需要提供
		* **None**: 默认设置
	* cv: 决定交叉验证所使用的分割策略。若输入值为None或整数，如果分类为二元或多分类，则会使用StratifiedKFold（分层的交叉验证），否则（非二元或多分类）将会使用KFold进行交叉验证
		* **None**: 使用默认5-fold交叉验证（默认设置）
		* int: 使用n-fold交叉验证
		* cross-validation generator or iterable: 通过model_selection中交叉验证进行设置的交叉验证对象
	* scoring: 用于对交叉验证测试集结果进行评估的策略
		* **None**: 默认设置
		* single score: 仅使用单一指标评估
			* str: 通过字符串设置评价指标（详细可见06.2.3-RFECV部分）
			* callable: 自定义指标，返回值为单一值
		* multiple score: 使用多种指标评估
			* list/tuple: 包含多个单一字符串设置的评价指标
			* callable: 自定义指标，返回值为字典（key为参数名字，value为参数得分）
			* dict: key为参数名字，value为callable
	* n_jobs: 是否使用多核进行
		* **None**: 不做设置（默认设置）
		* int: 使用设置核心数
		* -1: 使用所有核
	* pre_dispatch: 设置在进行并行作业时的分派的任务数量。当调度的任务多于CPU可以处理的数量时，可能会导致内存的激增，此时需减少该数值以避免内存的消耗
		* **"2*n_jpbs"**: 默认设置（该str可以改为任意与n_jobs相关的表达式）
		* None: 所有的任务立即创建并生成，适合轻量级、快速运行的作业
		* int: 指定同时产生总任务数
	* verbose: 控制输出信息的详细程度
		* **0**： 默认设置
	* fit_params: Parameters to pass to the fit method of the estimator
		* **None**: 默认设置
		* dict
	* error_score: 在估计器拟合发生错误时，评分的值。该参数不影响refit步骤
		* **np.nan**: 默认设置
		* "raise": 报错
		* numeric: 报错（FitFailedWarning）
* Returns
	* train_scores: 训练集得分
	* test_scores: 测试集得分
```python
import numpy as np
from sklearn.model_selection import validation_curve
from sklearn.datasets import load_iris
from sklearn.linear_model import Ridge

# 导入数据集
iris = load_iris()
x, y = iris.data, iris.target

# 随机打乱数据集
indices = np.arange(y.shape[0])
np.random.shuffle(indices)
x, y = x[indices], y[indices]

# 使用验证曲线计算得分
train_scores, valid_scores = validation_curve(Ridge(),
											  x=x,
											  y=y,
											  param_name="alpha",
											  param_range=np.logspace(-7,3,3),
											  cv=5)
```
#### 1.2.2 学习曲线
学习曲线用于评估使用**不同数量训练样本**时的训练和验证评分。其用于帮助发现增加更多的训练数据时模型的获益情况，以及估计是否受到更多来自方差误差或偏差误差的影响
如果在增加训练集大小时，验证分数和训练分数都收敛到一个很低值，说明**基于当前特征设置下**，将不会从更多的训练数据中获益

learning_curve
link: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html
* Parameters
	* estimator: 具有 fit 和 predict 方法的估计器对象
	* X: 特征集
	* y: 分类集
		* None: 用于非监督估计器
	* groups: 在分割训练集测试集时使用的分组标签，仅当在CV中选用相应方法（如 GroupKFold）时需要提供
		* **None**: 默认设置
	* train_sizes: 生成学习曲线样本的样本数目梯度。对于分类估计器，样本数目通常需较大，以包含来自每个类别中的至少一个样本
		* **np.linspace(0.1, 1.0, 5)**: [0.1, 0.325, 0.55, 0.775, 1]（默认设置）
			* np.linspace: 设置起始、终止和后生成均分的np.array
		* int: array中的int表示绝对数量
		* float: array中的float表示相对数量（比例）
	* cv: 决定交叉验证所使用的分割策略。若输入值为None或整数，如果分类为二元或多分类，则会使用StratifiedKFold（分层的交叉验证），否则（非二元或多分类）将会使用KFold进行交叉验证
		* **None**: 使用默认5-fold交叉验证（默认设置）
		* int: 使用n-fold交叉验证
		* cross-validation generator or iterable: 通过model_selection中交叉验证进行设置的交叉验证对象
	* scoring: 用于对交叉验证测试集结果进行评估的策略
		* **None**: 默认设置（使用正确率作为指标）
		* single score: 仅使用单一指标评估
			* str: 通过字符串设置评价指标（详细可见06.2.3-RFECV部分）
			* callable: 自定义指标，返回值为单一值
		* multiple score: 使用多种指标评估
			* list/tuple: 包含多个单一字符串设置的评价指标
			* callable: 自定义指标，返回值为字典（key为参数名字，value为参数得分）
			* dict: key为参数名字，value为callable
	* exploit_incremental_learning: 在估计器支持增强学习（incremental learning）时，此选项可助于加速训练集拟合
		* **False**: 估计器不支持增强学习或不开启（默认设置）
		* True: 开启
	* n_jobs: 是否使用多核进行
		* **None**: 不做设置（默认设置）
		* int: 使用设置核心数
		* -1: 使用所有核
	* pre_dispatch: 设置在进行并行作业时的分派的任务数量。当调度的任务多于CPU可以处理的数量时，可能会导致内存的激增，此时需减少该数值以避免内存的消耗
		* **"2*n_jpbs"**: 默认设置（该str可以改为任意与n_jobs相关的表达式）
		* None: 所有的任务立即创建并生成，适合轻量级、快速运行的作业
		* int: 指定同时产生总任务数
	* verbose: 控制输出信息的详细程度
		* **0**： 默认设置
	* shuffle: 在每次基于train_sizes进行训练集切割前，是否对训练集数据进行随机排列
		* **False**: 不进行随机排列（默认设置）
		* Ture: 进行随机排列
	* random_state: 随机数种子
	* error_score: 在估计器拟合发生错误时，评分的值。该参数不影响refit步骤
		* **np.nan**: 默认设置
		* "raise": 报错
		* numeric: 报错（FitFailedWarning）
	* return_times: 设置是否返回拟合及评估花费时间
		* **False**: 不返回（默认设置）
		* True: 返回
	* fit_params: Parameters to pass to the fit method of the estimator
		* **None**: 默认设置
		* dict
* Returns
	* train_sizes_abs: 用于生成学习曲线所使用的训练样本个数
	* train_scores: 训练集得分
	* test_scores: 测试集得分
	* fit_times: 拟合花费的时间（秒）（当return_times设置为Trues时才有返回值）
	* score_times: 评估花费的时间（秒）（当return_times设置为Trues时才有返回值）
```python
from sklearn.model_selection import learning_curve
from sklearn.svm import SVC

train_sizes, train_scores, test_scores = learning_curve(SVC(kernel="linear"),
														x=x,
														y=y,
														train_sizes=[50, 80, 110],
														cv=5)
```