# 2.创建分类器

分类与回归不同，回归的输出结果是实数，而分类则是用带标记的训练数据建立一个模型，然后对未知数据进行分类。解决分类问题时，都倾向解决**二元分类**问题，最简单的分类器是简单的**数学函数**，可以通过不同形式对其进行扩展，进而解决多元分类问题
## 2.1 建立简单分类器
```python
import numpy as np
import metplotlib.pyplot as plt

x = np.array([[3,1], [2,5], [1,8], [6,4], [5,2], [3,5], [4,7], [4,-1]])
y = [0, 1, 1, 0, 0, 1, 1, 0]

# 依据标签（y）类别对数据进行分类
class_0 = np.array([x[i] for i in range(len(x)) if y[i] == 0])
class_1 = np.array([x[i] for i in range(len(x)) if y[i] == 1])

# 以散点图的形式表现数据
plt.figure()
plt.scatter(class_0[:,0], class_0[:,1], color="black", marker="s")  # [:,0]代表x轴数据，[:,1]代表y轴数据
plt.scatter(class_1[:,0], class_1[:,1], color="black", marker="x")

# 创建一个最简单的线性分类器（即一个线性数学函数），并在图上表现出来
line_x = range(10)
line_y = line_X
plt.plot(line_x, line_y, color="black", linewidth=2)
plt.show()
```
## 2.2 建立逻辑回归分类器
逻辑回归：给定一组数据点，建立一个**在类之间绘制线性边界**的模型。逻辑回归可对训练数据派生的一组方程求解以提取边界
```python
import numpy as np
from sklearn import linear_model
import matplotlib.pyplot as plt

x = np.array([[4,7], [3.5,8], [3.1,6.2], [0.5,1], [1,2], [1.2,1.9], [6,2], [5.7,1.5], [5.4,2.1]])
y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])

# 建立逻辑回归分类器并使用数据对其进行训练
# solver：设置求解系统方程的算法类型
# C：正则化强度，代表对分类错误的惩罚值，数值越小代表强度越高。随着参数C的不断增大，分类错误的惩罚值越高。因此，各个类型的边界更优
classifier = linear_model.LogisticRegression(solver="liblinear", C=100)
classifier.fit(x, y)

# 获取数据点的边界，即在图形中想要使用的数值范围，通常是最小值-最大值；也可以增加一些余量
# 由于二维图使用的横纵坐标均来自于x，因此选取x、y的最大最小值时使用的是x的数值
# x[:,0]取矩阵中的第一列数值；x[:,1]取矩阵中第二列数值
x_min, x_max = min(x[:,0]) - 1.0, max(x[:,0]) + 1.0
y_min, y_max = min(x[:,1]) - 1.0, max(x[:,1]) + 1.0
step_size = 0.01  # 为了画出边界，需要使用grid数据求出方程的值
x_values, y_values = np.meshgrid(np.arange(x_min, x_max, step_size), np.arange(y_min, y_max, step_size))

# 计算分类结果
# np.c_：矩阵扩增列
mesh_output = classifier.predict(np.c_[x_values.ravel(), y_values.ravel()])
mesh_output = mesh_output.reshape(x_values.shape)  # 数组维度变形

# 画图
# 使用彩色区域画出各个分类类型的边界
plt.figure()
cm1 = plt.cm.get_cmap("gray")  # 设置使用一组颜色时，需要使用plt.cm.get_cmap()
plt.pcolormesh(x_values, y_values, mesh_output, cmap=cm1)
cm2 = plt.cm.get_cmap("Paired")
plt.scatter(x[:, 0], x[:, 1], c=y, s=80, edgecolors='black', linewidth=1, cmap=cm2)

# plt.xlim/ylim：设置坐标轴数值范围，标出坐标轴
plt.xlim(x_values.min(), x_values.max())
plt.ylim(y_values.min(), y_values.max())

# plt.xticks/yticks：设置坐标轴刻度范围，标出数值（使用int是为了取整数）
plt.xticks((np.arange(int(min(x[:, 0]) - 1), int(max(x[:, 0]) + 1), 1.0)))
plt.yticks((np.arange(int(min(x[:, 1]) - 1), int(max(x[:, 1]) + 1), 1.0)))
plt.show()
```
## 2.3 朴素贝叶斯分类器
贝叶斯分类的基础：贝叶斯定理
* 贝叶斯法则：假设**数据遵循某种概率分布**，通过对概率的分析推理以做出最优的决策
* 贝叶斯公式：
	* 利用古典数学理论，通过贝叶斯公式**依据先验概率和似然**来计算后验概率（即该假设属于某一类别的概率，类条件概率），之后选择后验概率最大的类作为该假设的目标值
	* P(c|X) = P(c)P(X|c) / P(X)
		* *P(c)*：先验概率
		* *P(X|c)*：样本X相对于类c的条件概率，即似然
		* *P(X)*：用于归一化的证据因子，对于所有类别都是恒定的

最大似然估计
* 估计类条件概率（后验概率）的常用策略：**假定后验概率具有某种确定的概率分布形式，再根据训练样本对概率分布的参数进行估计**。因此，贝叶斯分类**极度依赖于所假设的概率分布形式是否符合潜在的真实数据分布**
	* 假设对于某一类数据集 *Dc* 的条件概率，其具有某种概率分布形式，且被参数向量 *βc* 唯一确定，则可依据训练数据集来估计参数 *βc*。对 *βc* 进行最大似然估计就是寻找能最大化 *P(Dc|βc)* 的参数值 ***β'c***
	* 参数 *βc* 对于 *Dc* 的似然为：**P(Dc|βc) = ∏~(x∈Dc)~ P(x|βc)**
	* 上述连乘的操作容易造成**下溢**，可改用对数似然：**LL(βc) = logP(Dc|βc) = ∑~(x∈Dc)~ logP(x|βc)**
	* 据此，参数 *βc* 的最大似然估计为：**β'c = arg(βc)maxLL(βc)**

贝叶斯分类存在的问题
* 参数估计可以使类条件概率（后验概率）的估计变得简单，但结果的准确性**极度依赖于所假设的概率分布形式是否符合潜在的真实数据分布**，因此对于数据本身的先验知识的应用十分重要，**万不可使用单纯的猜测来假设概率分布形式**
* 对于类条件概率（后验概率）来说，由于它涉及**关于样本x所有属性的联合概率**，直接依据样本出现的频率来估计会遇到严重的困难。假设每个样本有d个特征，每个特征有m种可能，则样本空间就存在**m^d^**种可能性，而这一数量级必然远远大于训练的样本数m，这说明**很多样本的取值可能在训练样本中根本没有出现**。由于未被观测到和没有出现是两个不同的事件，所以**直接根据样本频率来估计类条件概率是显然不行的**
* 依据统计学可知，如果每个特征需要N个样本，则10个特征就需要N^10^个样本，1000个特征就需要N^1000^个样本，**所需样本数随着特征数目的增长而迅速增长**。而若**特征之间相互独立**，则所需样本数可减少至**1000\*N**，因此在贝叶斯分析中，往往假设各个特征之间是相互独立的

朴素贝叶斯分类器
* 朴素贝叶斯分类器是用贝叶斯定理进行建模的监督学习分类器
* 由上述贝叶斯分类存在的问题可知，使用贝叶斯分类最大的问题在于**类条件概率是所有属性上的联合概率，我们难以从有限的训练样本中直接估计得到**
* 据此，朴素贝叶斯分类器采用**特征条件独立性假设**，假设所有特征都是条件独立的，每个特征独立对分类结果产生影响，因此联合概率等于每个单独特征概率的乘积：**P(x|ck) = ∏P(xi|ck) = P(x1|ck) * P(x2|ck) * ...**，即 **P(x|ck) = P(ck)∏P(xi|ck)**
* 特征属性的条件概率估计
	* 特征是离散值时：统计训练样本中各个特征属性在每个类别中出现的频率
	* 特征是连续值时，可以假定其**服从高斯分布**
		* g(x, μ, σ) = (正态分布公式)
		* P(xk|ci) = g(xk, μci, σci)
		* 只要计算出训练样本中各个类别（c）中此特征项划分的各均值和标准差，带入上述公式即可得到需要的估计值
* 分类训练时需要注意的问题
	* 拉普拉斯校准（Laplace校准）
		* 若**某个特征值在训练集中在某个类中没有出现过，则类条件概率会等于零**，累成计算也即为零
		* 为避免这一问题，在计算概率值时需要进行平滑处理，以避免因训练样本不充足导致概率估值为零的问题，常用方法为拉普拉斯校准（Laplace校准），可将每个特征的出现数初始化为1，分母初始化为2
		* 当训练集充分大时，修正过程所引入的影响也可以变得可忽略，使估计值趋向于实际概率值
	* 取对数处理
		* 联合概率计算需要多个概率的乘积，其概率值都在0和1之间，连乘操作可能会发生**下溢出**
		* 取对数操作可将连乘变为加法，而对数函数和原函数**单调性一致不会产生任何损失**
* 优缺点
	* 优点
		* 容易建立且能很快做出决策
		* 计算简单
		* 可处理多类别数据
		* 决策结果容易解释
		* **当有新增样本数据时，仅对新样本属性值涉及的概率估值进行修正即可实现增量学习**
		* 在进行其他复杂分类计数前可以先应用朴素贝叶斯分类
		* 常用于文本分类
	* 缺点
		* **不适用于特征之间相关的情况**
		* 在假设不成立时，分类准确性降低

利用sklearn库建立一个简单的高斯朴素贝叶斯分类器
```python
import numpy as np
from sklearn.naive_bayes import GaussianNB
from logistic_regression import plot_classifier

x = []
y = []
with open('data.txt', 'r') as file:  # 从文本文件中读取数据
	for line in file:
		data = [float(x) for x in line.split(',')]  # 按文本文件分隔符将行转化为列表，提取x、y
		x.append(data[:-1])
		y.append(data[-1])

x = np.array(x)  # 特征项
y = np.array(y)  # 标签

# 建立高斯朴素贝叶斯分类器并进行训练、预测
# 高斯朴素贝叶斯分类器指定使用正态分布贝叶斯模型
classifier_gaussiannb = GaussianNB()
classifier_gaussiannb.fit(x, y)
y_predict = classifier_gaussianb.predict(x)

# 计算分类器准确性
accuracy = 100.0 * (y == y_predict).sum() / x.shape[0]

# 绘图
 plot_classifier(classifier_gaussiannb, x, y)  # 传入分类器、数据集
```
## 2.5 构建更好的分类模型
### 2.5.1 将数据分割为训练集和测试集（及验证集）
训练集和测试集
* 使用原因
	* 将数据集合理分配为训练集和测试集，可使用训练集的数据训练模型，然后用测试集上的误差作为**最终模型在应对现实场景中的泛化误差**，这样即可避免在部署环境和训练模型之间往复（代价往往较高），也可使用模型对测试数据的拟合程度作为近似代表模型泛化能力
	* 有了测试集，我们想要验证模型的最终效果，只需将训练好的模型在测试集上计算误差，即**可认为此误差即为泛化误差的近似**，我们只需让我们训练好的模型在测试集上的误差最小即可
* 使用训练集测试集注意
	* 常规数据分割：80%作为训练集，20%作为测试集
	* 需在**开始构建模型之前划分数据集，防止数据窥探偏误**。即避免因了解太多关于测试集样本的特点而导致模型测试得到更乐观（虚假的乐观）的结果
	* 在构建模型前进行的数据前处理，如数据清洗、数据特征缩放等操作**只能在训练集上进行**，**测试集将直接应用由训练集处理得到的参数**（如使用由训练集数据得到的中位数填补测试集中缺失值）
	* 进行模型选择时，可对比他们在测试集上的误差，选择**泛化能力强的模型**
* 数据集分割方法
	* 随机采样
		* 自己实现训练集测试集分割
        ```python
        import numpy as np
        def split_train_test(data, test_ratio, random_seed)
            np.random.seed(random_seed)  # 设置随机数种子

            shuffled_indices = np.random.pernutation(len(data))  # 随机生成0-len(data)随机序列

            test_size = int(len(data) * test_ratio)  # 计算测试集样本数
            # 此处针对随机序列生成训练、测试集，在返回值时要将其对其为原始data（使用iloc）
            train_indices = shuffled_indices[:test_size]
            test_indices = shuffled_indices[test_size:]
            return data.iloc[train_indices], data.iloc[test_indices]  # iloc选择参数序列中指定行
        ```
		* 使用sklearn库
        ```python
        from sklearn.model_selection import train_test_split

        x = datax  # 特征参数
        y = datay  # 标签参数

        # 对x和y使用相同的比例、随机数种子进行训练、测试集分割（确保分割的结果一一对应）
        x_train, x_test = train_test_split(x, test_size=0.2, random_state=42)
        y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)
        ```

	* 分层采样
以上两种数据集分割方式均为随机采样，这种方式对于**大量数据集**或**目标值分布均匀**的情况是可行的。而对于样本比例不均衡的样本（如二值分类器中，正例90%，反例10%），随机抽样会导致标签分布不均匀，模型训练效果不佳。针对此类模型，需要采用分层采样的方式进行划分数据集
		* 使用sklearn库
        ```python
        import numpy as np
        import pandas as pd
        from sklearn.model_selection import StratifiedShuffleSplit

        x = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
        y = np.array([0, 0, 1, 1])

        # n_splits：分割迭代的次数，只分割一次则设置为1即可
        split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)

        for train_index, test_index in split.split(x, y):  # split.split获取的是分割的index
            x_train, x_test = x[train_index], x[test_index]  # 由索引提取数据
            y_train, y_test = y[train_index], y[test_index]

        # 获取抽取的各个样本的比例
        train_data = pd.DataFrame(y_train)  # y_train可以转化为任意训练集、测试集
        train_data.info()  # 获取y_train的信息

        # 计算各个类别的比例
        # n为类别项所在的列编号。如果特征和标签分别储存在两个array中，则对y_train/y_test计算时，n=0
        print(train_data[n].value_counts() / len(train_data))
        ```

验证集
* 使用原因
	* 当并非进行两个模型之间的对比，而是**对模型本身进行选择**，如调整神经网络中的多个**超参数**时。一般来说，可使用**测试集**来检验不同超参数下的结果进行泛化误差估计。但可能模型在测试集上的误差为0，但是这样的模型部署到真实场景中去使用，效果可能会非常差。这样的现象称**信息泄露**
	* 信息泄露的一般性解释：在调整模型时，如果使用最终用于测试的数据集进行模型调整，相当于知道了考试题目并学会怎么做题（当人为调整“超参”使模型在测试集上误差最小，相当于教会了模型怎么去“做题”）。再使用这些数据进行测试时，模型理所应当地能获得很好的结果。测试集将数据信息泄露给模型的过程，即信息泄露
	* 为了应对信息泄露，在学习的时候，准备一些小测试来进行查漏补缺，用于调整模型的依据，这些小测试即**验证集**
	* 最终，调整模型时，**在训练集上训练模型，在验证集上评估模型，一旦找到的最佳的参数，就在测试集上最后测试一次**，测试集上的误差作为泛化误差的近似
	* 训练集、验证集、测试集比例设置
		* 数据量不是很大时（万以下）：6：2：2
		* 数据量很大：98：1：1
		* 数据量很少：采用一些高级的办法，如留出方、K-fold交叉验证等
### 2.5.2 使用交叉验证检验模型准确性
#### 2.5.2.1 交叉验证概述
在调整模型时，为了能让模型更加稳定，需使用数据集的不同子集进行反复的验证。如果只是针对特定子集进行调整，则可能会导致模型**过度拟合**。即，对于已知数据集拟合地很好，但对于未知数据集效果会大打折扣，为此，需要使用**交叉验证（cross-validation, CV）**

交叉验证的基本思想为：通过对**训练集**进行分割，生成**子训练集**和**子验证集**，使用子训练集对模型进行训练，使用子验证集对模型进行验证，最后再使用**测试集**对模型进行评估
* 举例：K-fold CV
	* K-fold CV将训练集划分为k个较小的集合（k-fold）
	* 在每次进行拟合时，使用k-1份集合作为子训练集，剩下的1份作为子验证集，重复进行k次
	* k-fold CV得到的性能指标是循环计算中每个值的平均值，其虽然计算代价很高，但是不会浪费太多的数据，在处理样本数据集较少的问题（例如，逆向推理）时比较有优势

计算交叉验证的方法
* corss_val_score(estimator, x, y, scoring, cv)
	* estimator：要进行评估的评估器（分类器、回归器、聚类器等）
	* x, y：投入计算正确率的数据，x_train, y_train或x_test, y_test
	* scoring：默认值为None，此时默认计算的是estimator的 ```score``` 方法。可以通过修改参数来改变评估方式和计算内容，具体见https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter，为要计算的项，依据不同模型（分类、回归、聚类）可有不同的参数
	* cv：交叉验证，默认值为5。当评估分类器，且y为分类标签时，交叉验证使用StraitifiedKFold，除此以外均使用KFold。此外，也可以传入一个交叉验证迭代器来使用其他交叉验证策略
	```python
	from sklearn.model_selection import corss_val_score
	from sklearn.model_selection import ShuffleSplit
	
	score = model_selection.cross_val_score(classifier, x, y, cv=5)
	
	# 传入其他交叉验证迭代器
	cv_shuffile = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)
	score = model_selection.cross_val_score(classifier, x, y, cv=cv_shuffile)
	```
* corss_validate(estimator, x, y, scoring, cv, return_train_score, return_estimator)
	* 各个参数的含义基本与 ```corss_val_score``` 相同
	* scoring：可传入含多个指标的**列表**。如果传入None，则默认值为 ```['test_score', 'fit_time', 'score_time']```，传入列表时，值为 ```['test_score1', 'test_score2', ..., 'fit_time', 'score_time']```
	* return_train_score：默认值为True，增加了所有scorers的训练得分keys
	* return_estimator：设置为True时，可保留所有在训练集上拟合好的估计器
	```python
	from sklearn.model_selection import cross_validate
	
	scoring = ['precision_weighted', 'recall_weighted']
	scores = cross_validate(classifier, x, y, scoring=scoring, cv=5)
	scores.keys()  # 输出传入的指标参数
	scores['test_recall_weighted']  # 从scores中查看指定参数（来自scores.keys()），会返回该参数计算的结果
	```
#### 2.5.2.2 交叉验证迭代器
##### 2.5.2.2.1 循环遍历数据的交叉验证迭代器

1.K-fold

K-fold将训练集（含n个样本）划分为k个较小的集合（k-fold），每个集合中包含 n/k 个样本在每次进行拟合时，使用k-1份集合作为子训练集，剩下的1份作为子验证集，重复进行k次
* k（下面的n_splits）的设置既影响**训练集分割数目**，也影响**重复进行数目**
* 若k=n，则K-fold等效于Leave one out策略
* **K-fold（及其衍生的各种类型）不受分类影响**
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.1.K-fold.png)
```python
from sklearn.model_selection import KFold

x = []  # 待分割的训练集数据
y = []

# n_splits：指定的k值（分割次数）
# shuffle：可选参数，值为True或False，决定分割数据集时是否采用随机的方式
kf = KFold(n_splits=2, shuffle=False)
for train, test in kf.split(x):  # 此处获得的仅为索引（使用x或y均可），还需进行下一步的分配
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
2.Repeated K-Fold

指定参数后，可重复运行 ```KFold``` n次，每次重复都会产生不同的分割。类似地， ```RepeatedStratifiedKFold``` 在每次重复中都将随机重复n次分层的K-Fold

```python
from sklearn.model_selection import RepeatedKFold

x = []  # 待分割的训练集数据
y = []

# n_splits：指定的k值
# n_repeats：K-fold重复执行的次数
# random_state：随机数种子
rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=0)
for train, test in rkf.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

3.Leave One Out (LOO) & Lave P Out (LPO)

LOO将训练集（含n个样本）划分为n-1个样本组成的子训练集和剩下的一个样本组成的子验证集。LOO是K-Fold中k=n时的特例
* 对于n个样本，可产生n个不同的训练集和n个不同的测试集
* 这类交叉验证不会浪费太多数据。但由于n个样本中有n-1个被用于训练，折叠所构建的模型实际上是相同的，且相当于从整个训练集建立的模型
* 作为一般规则，大部分作者和经验表明，5-fold或10-fold交叉验证要优于LOO

LPO与LOO十分相似，其从训练集（含n个样本）中删除p个样本来创建**所有可能的子训练/验证集**
* 与LOO、K-Fold不同，**当p设置大于1时，测试集的个体会发生重叠**
```python
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import LeavePOut

x = []  # 待分割的训练集数据
y = []

# LOO
loo = LeaveOneOut()
for train, test in loo.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
	
# LPO
lpo = LeavePOut(p=3)  # 设置剩下的样本数
for train, test in lpo.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

4.Shuffle & Split (随机排列交叉验证)

**设置指定的训练/验证集比例**后，原始训练集首先被打散，然后按照比例随机选择样本组成子训练/验证集

* 可用于替代K-Fold，因为其可控制子训练/验证集的比例划分
* 对于数据量较大的数据，需要注意分割次数
* **ShuffleSplit不受分类影响**
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.1.ShuffleSplit.png)
```python
from sklearn.model_selection import ShuffleSpilt

x = []  # 待分割的训练集数据
y = []

ss = ShuffleSpilt(n_splits=3, test_size=0.25, random_state=0)
for train, test in ss.split(x):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
##### 2.5.2.2.2 基于类标签、具有分层（y）的交叉验证迭代器
1.Stratified K-Fold

K-Fold的变种，在对训练集进行分割时，会返回分层的结果：每个小集合中，各个类别的样例比例大致和完整数据集中相同。```RepeatedStratifiedKFold``` 可用于在每次重复中都将随机重复n次分层的K-Fold
* 在类别略不均衡的情况下也可应用
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.2.StratifiedK-fold.png)
```python
from sklearn.model_selection import StratifiedKFold

x = []  # 待分割的训练集数据
y = []

# n_splits：分割次数
# shuffle：可选参数，值为True或False，决定分割数据集时是否采用随机的方式
skf = KFold(n_splits=2, shuffle=False)
for train, test in skf.split(x, y):  # 此处输入两个参数x、y，其中y用于提供数据的分层信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
2.Stratified Shuffle & Split

Shuffle & Split的变种，在对训练集进行分割时，会返回分层的结果。子集中每个类的比例都与完整数据集相同
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.2.StratifiedShuffleSplit.png)

```python
from sklearn.model_selection import StratifiedShuffleSplit

x = []  # 待分割的训练集数据
y = []

sss = StratifiedShuffleSplit(n_splits=3, test_size=0.25, random_state=0)  # 参数类别与ShuffleSplit相同
for train, test in sss.split(x, y):  # 此处输入两个参数x、y，其中y用于提供数据的分层信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```
##### 2.5.2.2.3 用于分组（group）数据的交叉验证迭代器
如果模型训练的结果依赖于样本的group，则进行的假设就不成立。举个例子，如果从多个患者身上收集数据，每个患者采集多个样本，此时如果收集的数据受到个体影响很大时，每个患者的ID就是组标识符（group identifier）。在这种情况下，我们想知道**在一组特定的group上训练的模型，是否能够很好地适用于未参与训练的group**，为此，需要确保**验证集中所有样本来自训练集中完全未出现的组**

1.Group K-Fold

K-Fold的变体，实现同一个group的数据不会在测试和训练集中同时出现
* 由于group数据可能不平衡，因此每次分割得到的子训练集和子验证集的大小并不完全相同
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.3.GroupK-fold.png)
```python
import numpy as np
from sklearn.model_selection import GroupKFold

x = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10])
y = np.array(["a", "b", "b", "b", "c", "c", "c", "d", "d", "d"])
groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

gkf = GroupKFold(n_splits=3)  # 分割次数
for train, test in gkf.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

2.Leave One Group Out (LOGO) & Leave P Group Out (LPGO)

LOO的变体，LO(P)GO将训练集（含n个样本）依据提供group的信息划分为n-1（n-p）个组的样本组成的子训练集和剩下的一（P）个组的样本组成的子验证集
* 提供的group信息需为整数组成的数组
```python
import numpy as np
from sklearn.model_selection import LeaveOneGroupOut, LeavePGroupsOut

x = np.array([1, 5, 10, 50, 60, 70, 80])
y = np.array([0, 1, 1, 2, 2, 2, 2])
groups = [1, 1, 2, 2, 3, 3, 3]

# LOGO
logo = LeaveOneGroupOut()
for train, test in logo.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
	
# LPGO
lpgo = LeavePGroupsOut(n_groups=2)  # 设置剩下的组数
for train, test in lpgo.split(x, y, groups=groups):
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

3.Group Shuffle Split
该方法是 ```ShuffleSplit``` 和 ```LPGO``` 的组合，其按照比例随机选择若干个组的样本组成子训练/验证集
![](E:\SynologyDrive\READING\CS\note\机器学习\img\2.5.2.2.3.GroupShuffleSplit.png)
```python
import numpy as np
from sklearn.model_selection import GroupShuffleSplit

x = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])
y = np.array(["a", "b", "b", "b", "c", "c", "c", "a"])
groups = [1, 1, 2, 2, 3, 3, 4, 4]

gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)
for train, test in gss.split(x, y, groups=groups):  # 此处输入参数追加了group，用于提供分组信息
	x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]
```

#### 2.5.2.3 常用评估模型的性能指标（使用cross_val_score）
举例：100个样本中，有82个是想让分类器选出的兴趣样本。最终，分类器从100个样本中挑选出73个它认为我们感兴趣的样本，而在73个样本中，只有65个是我们真正感兴趣的样本
* 精度（precision）
	* 被分类器正确分类的样本数量占分类器总分类样本数量的百分比
	* 精度 = 65/73 = 0.89 （分子为分类正确样本，分母为模型挑选样本数）
* 召回率（recall）
	* 被分类器正确分类的样本数量占该分类总样本数量的百分比
	* 召回率 = 65/82 = 0.79 （分子为分类正确样本，分目为该类型样本总数）
* F1得分（F1 score）
	* 一个优秀的机器学习模型需要同时具备良好的精度和召回率，但二者是**二律背反**的，因此，引入F1得分作为精度和召回率的合成指标，实则为精度和召回率的调和均值
	* F1 = 2×精度×召回率 / (精度+召回率)
	* F1 = 2×0.89×0.79/(0.89+0.79) = 0.8370
```python
from sklearn.model_selection import corss_val_score

# 正确率
accuracy = cross_val_score(classifier, x, y, scoring='accuracy', cv=5)
# 精度
# weighted指加权平均，下同
precision = cross_val_score(classifier, x, y, scoring='precision_weighted', cv=5)
# 召回率
recall = cross_val_score(classifier, x, y, scoring='recall_weighted', cv=5)
# F1得分
f1 = cross_val_score(classifier, x, y, scoring='f1_weighted', cv=5)
```
### 2.5.3 混淆矩阵可视化
混淆矩阵用于理解分类模型性能，用于了解数据的错误分类情况
```python
from sklearn.metrics import confusion_matrix

y_true = [1, 0, 0, 2, 1, 0, 3, 3, 3]
y_pred = [1, 1, 0, 2, 1, 0, 1, 3, 3]

# 使用测试集真实值和预测值生成混淆矩阵
confusion_mat = confusion_matrix(y_true, y_pred)  # para1：真实值，para2：预测值

# 绘图表示混淆矩阵
def plot_confusion_matrix(confusion_mat):
	# 绘图
	cm = plt.cm.get_cmap("Greys_r")  # 使用黑-白bar
	plt.imshow(confusion_mat, interpolation='nearest', cmp=cm)  # 传入颜色需要单独传入
	plt.colorbar()
	
	# 设置绘图参数
	plt.title('Confusion matrix')
	tick_marks = np.arange(4)  # 用于设置坐标轴的刻度
	plt.xticks(tick_marks, tick_marks)
	plt.yticks(tick_marks, tick_marks)
	plt.ylabel('True label')
	plt.xlabel('Predicted label')
	plt.show()

plot_confusion_matrix(confusion_mat)
```
### 2.5.4 直接提取性能报告
直接在控制台打印精度、召回率、F1得分
```python
from sklearn.metrics import classification_report

y_true = [1, 0, 0, 2, 1, 0, 3, 3, 3]
y_predict = [1, 1, 0, 2, 1, 0, 1, 3, 3]
target_names = ['class-0', 'class-1', 'class-2', 'class-3']

print(classification_report(y_true, y_predict, target_names=target_names))
```
## 2.6 分类器示例：使用随机森林分类器依据汽车特征评估汽车质量
### 2.6.1 使用随机森林分类器依据汽车特征评估汽车质量
```python
import numpy as np
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn import model_selection

# 导入文件
inputfile = "E:/SynologyDrive/READING/CS/note/机器学习/test Data/02.car.data"
x = []
with open(inputfile, "r") as file:
    for line in file.readlines():
        data = line[:-1].split(",")  # 不要最后一项：最后一项为换行符
        x.append(data)
x = np.array(x)  # 将导入的数据转化为数组

# 将字符串转化为数值
label_encoder = []
x_encoded = np.empty(x.shape)  # 创建与导入的x形状相同数组，用于储存转化为数值的特征值

for i, item in enumerate(x[0]):  # 没有用到item，只用到i索引列
    label_encoder.append(preprocessing.LabelEncoder())  # 对每一列单独创建一个标签编码对象，储存在列表中
    x_encoded[:,i] = label_encoder[-1].fit_transform(x[:,i])  # [:,i]获取array的列，一整列为一维
x = x_encoded[:,:-1].astype(int)  # [:,:-1]获取array除最后一列的其他列，将类型转化为整数
y = x_encoded[:,-1].astype(int)  # [:,-1]获取array的最后一列，将类型转化为整数

# 训练分类器
paras = {'n_estimators': 200, 'max_depth': 8, 'random_state': 5}  # 将函数的参数储存于字典中
rfclassifier = RandomForestClassifier(**paras)  # 将储存在字典的参数传入函数，创建分类器
rfclassifier.fit(x, y)  # 训练分类器

# 进行交叉验证
accuracy = model_selection.cross_val_score(rfclassifier, x, y, scoring='accuracy', cv=3)
print("Accuracy is {} %".format(str(round(100*accuracy.mean(), 2))))  # 交叉验证产生多个结果，需取均值
>>> Accuraacy is 78.65 %


# 使用测试数据进行测试（单一样本）
inputdata = ['vhigh', 'vhigh', '2', '2', 'small', 'low']
# 输入特征值并转化为数组（如果仅有一行，则需行转化为列）
inputdata_arary = np.array(inputdata).reshape(len(inputdata), 1)
# 以输入数据的形状创建一个数组，用于储存转化为数值的特征值（如果仅有一行，则需行转化为列）
inputdata_encoded = np.array([-1] * len(inputdata)).reshape(len(inputdata), 1)

for i, item in enumerate(inputdata_arary):
    # 对每一项（i）内容，使用之前已有的编码字典（label_encoder[i]）编码（transform，而非fit_transform）
    # 将编码后的特征值转化为整数后，储存在列表指定项中
    inputdata_encoded[i] = int(label_encoder[i].transform(inputdata_arary[i]))
# 若为单样本（单行），则需转化为二维数组（训练时投入的是二维数组）
inputdata_encoded = inputdata_encoded.reshape(1,-1)

y_predict = rfclassifier.predict(inputdata_encoded)  # 进行数值预测
y_predict_class = label_encoder[-1].inverse_transform(y_predict)  # 使用最后一列的编码器（-1）解码标签
print("Output class: {}".format(y_predict_class))


# 使用测试数据进行测试（多样本）
inputdata2 = [['vhigh', 'vhigh', '2', '2', 'small', 'low'], ['low', 'low', '5more', 'more', 'big', 'high']]
# 输入特征值（需转化为数组）
inputdata_arary = np.array(inputdata)
# 以输入数据的性质创建一个内容全为-1的数组，用于储存转化为数值的特征值
inputdata_encoded = np.ones(inputdata_arary.shape)

for i in range(inputdata_arary.shape[1]):  # 以矩阵列数为索引
    # 对每一列（:,i）内容，使用之前已有的编码字典（label_encoder[i]）编码（transform，而非fit_transform）
    # 将编码后的特征值储存到列表指定项中
    inputdata_encoded[:,i] = label_encoder[i].transform(inputdata_arary[:,i])
inputdata_encoded.astype(int)  # 也可不要，原因未知

y_predict = rfclassifier.predict(inputdata_encoded)  # 进行数值预测
y_predict_class = label_encoder[-1].inverse_transform(y_predict)  # 使用最后一列的编码器（-1）解码预测值
print("Output class: {}".format(y_predict_class))
```
### 2.6.2 生成验证曲线调整超参数n_estimators、max_depth
在随机森林分类器中，有两个**超参数**：```n_estimators``` 和 ```max_depth```，它们决定了分类器的性能。在对模型进行调试时，实际上就是在调整超参数，而验证曲线的可以通过只调整感兴趣的超参数，保持其他参数不变的方式理解**每个超参数对训练得分的影响**
* 参数：参数是**模型内部**的配置变量，**通常由过去的训练数据总结得到**
	* 模型在进行预测时需要它们
	* 它们的值定义了可使用的模型
	* 它们是从数据中估计或获悉的
	* 它们**通常不由编程者手动设置**
	* 它们通常被保存为学习模型的一部分
	* **最优化算法**是估计模型参数的有效工具
	* 示例：神经网络中的权重、支持向量机中的支持向量、线性回归或逻辑回归中的系数
* 超参数：超参数是**模型外部**的配置变量，**其值无法从数据中估计**，需要**人为指定**
	* 它们通常用于**帮助估计模型参数**
	* 它们通常由人工指定
	* 它们通常可以使用启发式设置
	* 它们经常被调整为给定的预测建模问题
	* 示例：训练神经网络的学习速率、支持向量机的C、sigma、K最近邻估计的K

validation_curve
```python
# 接上一节随机森林分类器
import numpy as py
from sklearn.model_selection import validation_curve
import matplotlib.pyplot as plt

# 固定max_depth
classifier = RandomForestClassifier(max_depth=4, random_state=7)  # 固定max_depth为4
parameter_grid = np.linspace(25, 200, 8).astype(int)  # n_estimators在25-200范围内，每隔8个值迭代一次
train_scores, validation_scores = validation_curve(classifier, x, y, "n_estimators", parameter_grid, cv=5)

print("\nParam: n_estimators\nTraining scores:\n", train_scores)
print("\nParam: n_estimators\nValidation scores:\n", validation_ scores)

plt.figure()
plt.plot(parameter_grid, 100*np.average(train_scores, axis=1), color="black")  # 此处只绘制训练曲线
plt.xlabel("Number of estimators")
plt.ylabel("Accuracy")
plt.show()

# 固定n_estimators
classifier = RandomForestClassifier(n_estimators=20, random_state=7)  # 固定n_estimators为20
parameter_grid = np.linspace(2, 10, 5).astype(int)  # max_depth在2-10范围内，每隔5个值迭代一次
train_scores, validation_scores = validation_curve(classifier, x, y, "max_depth", parameter_grid, cv=5)

print("\nParam: n_estimators\nTraining scores:\n", train_scores)
print("\nParam: n_estimators\nValidation scores:\n", validation_scores)

plt.figure()
plt.plot(parameter_grid, 100*np.average(train_scores, axis=1), color="black")
plt.xlabel("Maximum depth of the tree")
plt.ylabel("Accuracy")
plt.show()
```
### 2.6.3 生成学习曲线调整训练集大小

学习曲线用于显示估计器在**使用不同数量训练样本时的训练和验证评**分，这一评分可以帮助发现**增加训练集数据对模型的获益**，以及估计是否会受到更多来自**方差误差**或**偏差误差**的影响

如果在增加训练集大小时，训练分数和验证分数能够收敛到一个很低的值，那增加训练集数量对模型的作用不大
* 在进行总体评估时，还需要考虑样本总量的规模等因素
* 虽然训练集规模越小，训练准确性越高，但它们也容易导致过度拟合
```python
import numpy as py
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt

classifier = RandomForestClassifier(random_state=7)
parameter_grid = np.array([200, 500, 800, 1000])  # 样本数范围设置为200-1000
train_sizes, train_scores, validation_scores = learning_curve(classifier, x, y, train_sizes=parameter_grid, cv=5)

print("\nTraining scores:\n", train_scores)
print("\nValidation scores:\n", validation_scores)

plt.figure()
plt.plot(parameter_grid, 100*np.average(train_scores, axis=1), color="black")
plt.plot(parameter_grid, 100*np.average(validation_scores, axis=1), color="red")
plt.xlabel('Number of training samples')
plt.ylabel('Accuracy')
plt.show()
```
## 2.7 一些小补充

## 2.7.1 对矩阵数据编码：非数值型编码，数值型保留为数值型

```python
x = np.array(x)

label_encoder = []  # 储存对每一列非数值型编码的编码器
x_encoded = np.empty(x.shape)  # 创建与x形状相同的矩阵，用于储存编码后数据

for i, item in enumerate(x[0]):  # 以一行数据为例获取列索引和数据类型即可，故x[0]即可
	if item.isdigit():  # 如果是数值型，不编码且保留
		x_encoded[:,i] = x[:,i]
	else:  # 非数值型，进行编码，且保留编码器
		label_encoder.append(preprocessing.LabelEncoder())
		x_encoded[:,i] = label_encoder[-1].fit_transform(x[:,i])

x = x_encoded[:,:-1].astype(int)  # 提取特征列
y = x_encoded[:,-1].astype(int)  # 提取标签列
```