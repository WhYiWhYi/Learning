## 多进程

在使用多进程时，每个核上的进程是并行的。在使用多进程时，需要先了解计算机CPU的处理器个数，但进程数大于CPU内核数时，等待运行的进程会等到其他进程运行完毕将内核让出来。一般来说，进程数设置为计算机内核数较为合理。需要注意的是， **新创建的进程与进程的切换会消耗资源，故一般进程数不易开太大**
**对于CPU密集型，程序偏重于计算，如科学计算、机器学习等，建议使用多进程**
### 直接创建简单多进程（使用multiprocessing的Process方法直接创建）

multiporcessing.Process(target=, args=)
* target：接收加入进程的函数名
* args：加入进程的函数所需要的参数；参数储存在元组中 ```(para1, para2, ...)```，当只有一个参数时，在参数末尾要加逗号 ```(para1,)```
```python
import os
import time
from multiprocessing import Process

def squarecalc(i):
	print("子进程：{} - 任务 {}".format(os.getpid(). i))  # os.getpid获取现在使用的进程
	square = i **20
	print("结果：{}".format(square))
	
if __name__ == "__main__":
	print("当前母进程：{}".format(os.getpid()))  # 获取母进程
	start = time.time()
	
	# 使用Process方法创建子进程
	p1 = Process(target=squarecalc, args=(1,))  # 使用关键字传参，由于函数参数只有一个，故使用(1,)形式
	p2 = Process(target=squarecalc, args=(2,))
	
	# 开始执行子进程
	p1.start()
	p2.start()
	
	p1.join()  # 单一子进程结束后，使用join方法阻塞母进程，从而直到所有子进程执行完毕后才执行后续步骤
	p2.join()
	
	end = time.time()
	print("总共耗时：{} s".format(end-start))
```
### 使用类来创建多进程（继承Process自定义进程类）
```python
import time
from multiprocessing import Process

class MyProcess(Process):  # 继承Process类
	def __init__(self, name):
		super().__init__()  # 调用Process父类中的构造函数
		self.name = name
	
	def run(self):
		print("Process name is {}".format(self.name))
		time.sleep(1)

if __name__ == "__main__":
	for i in range(3):  # 决定创建的进程数目
		p = MyProcess(i)  # 使用i传入MyProcess类创建新的进程，此处总共创建三个
		p.start()  # 开启进程
		
	for i in range(3):
		p.join()  # join不可紧跟在start后，这样会一个进程完全结束才开启下一个进程，失去进程的意义
```
### 使用进程池的多进程（使用multiprocessing的Pool类）
进程数较少时，可以手动创建多个进程，而当进程数多的时候，可以使用进程池Pool创建进程，同时还可通过传递参数限制并发进程的数量。当有新的请求提交到pool中时，如果池还没满，则可创建一个新的进程来执行该请求，若池中进程数已经达到规定的最大值，则请求就会继续等待，直到池中的进程结束方可创建新的进程
阻塞和非阻塞：
阻塞和非阻塞关注的是程序在等待调用结果（消息、返回值等）时的状态

* 阻塞：等到回调结果出来，在有结果前，当前进程会被挂起
* 非阻塞：添加进程后，不一定非要等到结果出来就可以添加其他进程运行（当然是非阻塞式更好啦！）

Pool类中常用的方法
* apply_async(func, args, kwds)
	* 默认方法，使加入进程池的函数以非阻塞的方式异步执行（并行）。其向进程池提交需要执行的函数及参数
	* func：要加入进程的函数
	* args：加入进程的函数所需使用的参数
* close()
	* 关闭进程池，使其不再接收新的任务
* terminate()
	* 结束所有的工作任务，未处理的任务不再处理
* join()
	* 阻塞主进程，等待子进程退出。join方法需在close或terminate之后使用（确保所有子进程结束）
```python
import time
import os
from multiprocessing import Pool, cpu_count

def squarecalc(i):
	print("子进程：{} - 任务 {}".format(os.getpid(), i))  # os.getpid获取现在使用的进程
	square = i **20
	print("结果：{}".format(square))

if __name__ == "__main__":
	print("CPU内核数：{}".format(cpu_count()))  # cpu_count可获取CPU的内核数目
	print("当前母进程：{}".format(os.getpid()))  # 获取母进程
	start = time.time()
	
	pool = Pool(processes=4)  # 创建进程池，进程池中包含4个进程（CPU数目）
	for i in range(4):  # range数目决定了运行次数
		# 将函数传入子进程，并直接运行
		# 若子进程中运行函数速度极快，则该进程可能重新投入进程池反复运算
		# 不同进程中可以同时调用同一个函数
		# 当传入进程池的任务数目大于进程池中进程数时，多出的部分会等待之前的进程结束后重新安排
		# 以此处为例，当需要的进程数为5或8时，所使用的时间相同，因为多出的1个和4个是同时运行的，因此执行任务的数量可以根据核数来考虑，尽量不要遗漏
		pool.apply_async(squarecalc, args=(i,))  # 传入函数时不用再使用关键字参数，直接输入函数名
	
	pool.close()  # 关闭进程池
	pool.join()  # 阻塞母进程，等待所有子进程
	
	end = time.time()
	print("总共耗时：{} s".format(end-start))
```
### 获取进程调用函数的返回值

若加入进程执行的函数有返回值，提取返回值时需要使用get方法。在需要提取值时可以将整个调用多进程的过程封装到函数中，函数的返回值设置为加入进程执行函数的返回值
```python
from multiprocessing import Pool

def getResult():
	listprocesses = []
	pool = Pool(processes=4)
	for i in range(4):
		# 当任务数大于池进程数时，加入列表的顺序为依次加入
		listprocesses.append(pool.apply_async(squarcalc, args=(i,)))  # 进程加入列表中
	
	listresults = []
	for item in listprocesses:  # item指进程调用函数后的结果，是multiprocessing.pool.ApplyResult对象
		r = item.get()  # 获取函数结果
		listresults.append(r)  # 储存每次调用函数的结果
	
	pool.close()
	pool.join()
	return listresults
```
### 多进程通信——使用Process+Queue的多进程（使用Queue队列进行进程间的数据传递）

Queue队列类似于管道，元素先进先出，可分为以下四类
* queue.Queue：先进先出队列（队列中元素按顺序出）
* queue.LifoQueue：后进先出队列（队列中的元素按反顺序出）
* queue.PriorityQueue：优先级队列
	* 优先级队列在填充数据时使用元组，```(优先级, 数据)```。优先级越小，级别越高，取出时优先取高级别
* queue.deque：双线队列

Queue队列对象的方法：
* q.put：向队列中填充数据。默认参数为 ```block=True```、 ```timeout```，当 ```block=True``` 时，写入是阻塞式的，阻塞时间由 ```timeout``` 确定。当队列q被填充满时，代码便会阻塞，直到其他程序来取走数据
* q.get：从队列中取数据。默认为阻塞式
* q.empty：如果队列为空，返回 ```True```，否则返回 ```False```，用于进行判断
* q.full：如果队列满了，返回 ```True```，否则返回 ```False```，用于进行判断
* q.qsize：显示队列中存在的元素的长度
* q.maxsize：显示队列最大支持长度，使用时无括号
* q.join：意味着等到队列为空，再执行别的操作

```python
# 两个独立进程：写入子进程 (pw)和读取子进程 (pr)共享父进程下队列Queue的例子
import time, os, random
from multiprocessing import Process, Queue  # multiprocessing中自带了Queue库，这与threading不同

def write(q):  # 将元素写入队列中
    print('Process to write: {}'.format(os.getpid()))
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)  # 在子进程中将数据写入父进程创建的队列
        time.sleep(random.random())

def read(q):  # 将元素从队列中提取
    print('Process to read:{}'.format(os.getpid()))
    while True:
        value = q.get(True)  # 在子进程中从写入了数据的父进程的队列中提取队列数据
        print('Get %s from queue.' % value)

if __name__=='__main__':
    q = Queue()  # 队列的创建需在父进程中，之后传入子进程，以达到在子进程间通信的作用
    
    pw = Process(target=write, args=(q,))  # 将空队列传入子进程，写入数据
    pr = Process(target=read, args=(q,))  # 将写入数据的队列传入子进程，提取数据

    pw.start()
    pr.start()
   
    pw.join()   # 等待pw结束
    pr.terminate()  # pr进程里是死循环，无法等待其结束，只能强行终止

>>>Process to write: 3036  # 开启子进程pw
>>>Put A to queue...  # 执行pw的第一项
>>>Process to read:9408  # 开启子进程pr
>>>Get A from queue.  # 执行pr第一项
>>>Put B to queue...
>>>Get B from queue.
>>>Put C to queue...
>>>Get C from queue.
```
### 多进程通信——使用Pool+Queue的多进程
要将进程池Pool与Queue结合，Queue的使用方式需要改变。追加使用 ```Manager```和 ```Queue```一同创建、管理队列，实现父进程与子进程、子进程与子进程之间的通信
```python
import time
from multiprocessing import Pool, Manager

listq = ["a", "b", ...]  # 要向队列中添加的、用于函数执行的内容

def fuction(q):  # 进程需要执行的函数
	print("当前运行的进程为 {}".format(os.getpid()))
	ele = q.get()
	time.sleep(2)
	print("从队列中取出的元素为：{}".format(ele))

if __name__ == "__main__":
	print("母进程为 {}".format(os.getpid()))
	# 使用Manager和Queue创建和管理队列
	manager = Manager()
	q = manager.Queue()
	
	for i in listq:
		q.put(i)  # 向队列中添加元素
	
	qsize = q.qsize()  # 获取队列数目
	
	pool = Pool(processes=4)  # 创建进程池，进程池中包含4个进程（CPU数目）
	for i in range(qsize):
		# range数目决定了运行次数，对于使用队列的多进程来说，也就是取决于队列内元素的数目，即队列大小
		# 由于在function函数每次只取出队列中的一个元素，因此把队列中内容全部运行的次数即队列大小
		pool.apply_async(function, args=(q,))  # 传入函数时不用再使用关键字参数，直接输入函数名
	
	pool.close()  # 关闭进程池
	pool.join()  # 阻塞母进程，等待所有子进程
```



## 多线程
在使用多线程时，理论上可开启任意数目的线程，每调用一次开启线程的方法（可以直接调用 ```Thread```，也可以是调用继承了 ```Thread``` 的自己的类），就会开启一个新的线程。用户并不能保证线程开始、结束的顺序（尤其是在耗时较短的任务中），但是如果在获取调用函数的结果时，可以按顺序得到结果
推荐使用继承 ```Thread```  类的方式构建自己的多线程类，可进行一定功能的自定义
**对于I/O密集型，程序需要频繁进行输入输出操作，如爬虫，建议使用多线程**
### 直接创建简单多线程（使用threading的Thread方法直接创建）
Thread方法与Process方法类似，也是接收两个参数
threading.Thread(target=, args=)
* target：接收加入进程的函数名
* args：加入进程的函数所需要的参数；参数储存在元组中 ```(para1, para2, ...)```，当只有一个参数时，在参数末尾要加逗号 ```(para1,)```
```python
import time
from threading import Thread

def squarecalc(i):
	print("当前子线程：{} - 任务 {}".format(threading.current_thread().name, i))  # 获取正在进行线程名
	square = i **20
	print("结果：{}".format(square))

if __name__ == "__main__":
	print("当前主线程：{}".format(threading.current_thread().name))
	start = time.time()
	
	threadlist = []  # 储存分配线程的列表，列表中储存的是Thread，不是函数计算的结果
	for i in range(1,5):
		t = Thread(target=squarecalc, args=(i,))  # 此处的t是Thread
		threadlist.append(t)
	
	for t in threadlist:  # 开启各个线程
		t.start()
	
	for t in threadlist:  # 使主线程等待子线程结束实现线程同步
		t.join()
	
	end = time.time()
	print("总共耗时：{} s".format(end-start))
```
默认情况下，主线程和子线程的运行独立且互不干涉，若希望主线程等待子线程实现线程同步，则需使用join方法。而如果希望主线程结束时不再继续执行子线程，则使用如下方法
```python
if __name__=='__main__':

    for i in range(5):
        t = threading.Thread(target=squarecalc, args=(i,))
        t.setDaemon(True)  # 主线程结束时不再执行子线程
        t.start()
```
### 使用类创建多线程（继承Thread类，可自定义获取线程调用函数时的返回值）
可通过继承Thread类自定义创建多线程的子类，在子类中自定义获取函数返回值的方法 ```getresult```
需要注意的是，在获取结果时，需要先对各个线程进行阻塞，等待主线程。若子进程需要执行一段时间才能获得的结果，而主进程不会等待而直接进入获取结果的步骤，则获取的结果很可能为None值
```python
from threading import Thread

def squarecalc(i):
	print("当前子线程：{} - 任务 {}".format(threading.current_thread().name, i))  # 获取正在进行线程名
	square = i **20
	print("结果：{}".format(square))

class MyThread(Thread):  # 继承Thread类，构建自己的MyThread子类
	def __init__(self, func, args):
		super().__init__()  # 调用Thread父类中的构造函数
		self.func = func  # MyThread实例在线程中调用的函数
		self.args = args  # MyThread实例在线程中调用的函数所需的参数
		
	def run(self):  # run函数，用来执行实例在线程中调用的函数
		self.result = self.func(*self.args)
	
	def getresult(self):
		try:
			return self.result  # 用于获取返回值
		except:
			return None

if __name__ == "__main__":
	print("当前主线程：{}".format(threading.current_thread().name))
	start = time.time()
	
	listthread = []  # 储存分配线程的列表，列表中储存的是MyThread，不是函数计算的结果
	for i in range(1,5):  # 决定创建的线程数目（类似不使用Pool的多进程，创建数目与range相关）
		t = MyThread(func=squarecalc, args=(i,))  # 此处的t是Thread。在继承中参数改变，target→func
		listthread.append(t)
	
	for t in listthread:  # 开启各个线程。若线程较多时可使用for循环的方式
		t.start()
	
	for t in listthread:  # 使主线程等待子线程结束实现线程同步，如果不等待，结果获取可能为None
		t.join()
		
	listresults = []
	for thread in listthread:
		result = thread.getresult()  # 使用自定义方法获取函数的结果
		listresults.append(result)
	print(listresults)
	
	end = time.time()
	print("总共耗时：{} s".format(end-start))
```
### 多线程通信——使用Thread+Queue的多进程

与multiprocessing不同，threading中并未内置Queue，需要从单独导入queue
```python
# 以经典的生产者、消费者通信为例
from threading import Thread
from queue import Queue

def producer(q, i):  # 生产者，向队列中放入元素（由于是while True，故是无限放入）
	while True:
		time.sleep(0.5)  # 设置每0.5秒向队列中加入一个新的元素
		q.put(i)
		print("Producer: {}".format(q.put(i)))

def consumer(q, i):  # 消费者，从队列中取出元素（由于是while True，故是无限提取）
	while True:
		time.sleep(1)  # 设置每1秒从队列中取出一个新的元素
		q.get(i)
		print("Consumer: {}".format(q.get(i)))

if __name__ == "__main__":
	q = Queue(10)  # 创建一个大小为10的队列
	
	for i in range(20):
		tp = Thread(target=producer, args=(q,i))
		tc = Thread(target=consumer, args=(q,i))
	
	tp.start()
	tc.start()
```
将生产者函数和消费者函数改为继承自 ```Thread``` 类的生产者类、消费者类，使用Queue实现通信
```python
import time
from threading import Thread
from queue import Queue

class Producer(threading.Thread):  # 生产者类
    def __init__(self, name, queue):
        super().__init__(name = name)  # 调用父类的构造函数，同时指定在继承类中调用父类中的name参数
        self.queue = queue

    def run(self):
    	# 向队列中放入元素，与上述不同的是，这是一个有限放入
        for i in range(1, 5):  # 向队列中放入4个元素
            print("{} is producing {} to the queue!".format(self.getName(), i))
            self.queue.put(i)
            time.sleep(1)  # 每次放入后休息1秒
        print("%s finished!" % self.getName())
    
class Consumer(threading.Thread):  # 消费者类
    def __init__(self, name, queue):
        super().__init__(name = name)  # 调用父类的构造函数，同时指定在继承类中调用父类中的name参数
        self.queue = queue

    def run(self):
        for i in range(1, 5):  # 从队列中提取元素
            val = self.queue.get()
            print("{} is consuming {} in the queue.".format(self.getName(), val))
            time.sleep(2)  # 每次提取后休息2秒（保证慢于生产者的生产速度）
        print("%s finished!" % self.getName())

if __name__ == "__main__":
	q = Queue()
	producer = Producer("Producer", q)
	consumer = Consumer("Consumer", q)
	
	producer.start()
	consumer.start()
	
	producer.join()
	consumer.join()
	print('All threads finished!')
```



## 协程
协程的优势：
* 协程像一种在程序级别模拟系统级别的进程，由于其是单线程且少了上下文切换，因此相对来说系统消耗少，速度快
* 协程方便切换控制流，可简化编程模型。协程可保留上一次调用时的状态（所有局部状态的一个特定组合），每次过程重入时，就相当于进入了上一次调用的状态
* 协程具有高扩展性和高并发性，一个CPU甚至可支持上万协程（可以随意创建多个协程）

协程的缺点
* 协程本质是一个单线程，不能同时使用单个CPU的多核，需要和进程配合才能运行在多CPU上
* 有长时间阻塞的IO操作时，可能会阻塞整个程序，此时最好不要使用协程

使用yield生成器也可运用协程，但此处只讨论由gevent库创建的协程。gevent创建的协程要比用传统的线程高，甚至高很多。其基本思想为：当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO

gevent方法：
* gevent.spawn()：创建一个普通的Greenlet对象并切换
* gevent.spawn_later(seconds=3)：延时创建一个普通的Greenlet对象并切换
* gevent.spawn_raw()：创建的协程对象属于一个组
* gevent.getcurrent()：返回当前正在执行的greenlet
* gevent.joinall(jobs)：将协程任务添加到事件循环，接收一个任务列表
* gevent.wait()：可以替代join函数等待循环结束，也可以传入协程对象列表
* gevent.kill()：杀死一个协程
* gevent.killall()：杀死一个协程列表里的所有协程
* monkey.patch_all()：非常重要，会自动将python的一些标准模块替换成gevent框架

针对Greenlet对象（job）的方法：
* 启动协程
	* job.start()：将协程加入循环并启动协程
	* job.start_later(3)：延时启动协程
* 等待任务完成
	* job.join()：等待任务完成
	* job.get()：获取协程返回的值；等效于job.value
* 判断任务状态
	* job.dead()：判断协程是否死亡
	* job.kill()：杀死正在运行的协程并唤醒其他协程
	* job.ready()：任务完成返回真
	* job.successful()：任务成功完成返回真，否则抛出错误
* 获取对象的属性
	* job.value：获取返回值；等效于job.get()
	* job.loop：时间循环对象
```python
# 一个补丁patch_all,注意要放在所有的import前面，其会将线程、进程替换成gevent框架，使得以用同步编程的方式编写异步代码
from gevent import monkey;monkey.patch_all()
import gevent

def add(n, m):
	r = n + m
	return r

if __name__ == "__main__":
	jobs = []
	for i in range(3):
		# gevent.spawn的两个参数为：调用的函数、函数的参数（多参数顺序排列，无需放入元组中）
		# gevent.spawn得到的结果是一个Greenlet对象，将对象加入到列表中
		jobs.append(gevent.spawn(add, i, i+1))
		
	gevent.joinall(jobs)  # 方便地将协程任务列表添加到事件循环，类似于进程和线程的join，也可以一个一个任务join
	
	listresults = []
	for job in jobs:
		res = job.value  # 取得结果，注意value后面没有括号
		listresults.append(res)
	print(res)
```